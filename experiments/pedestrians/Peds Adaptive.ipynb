{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Online Adaptive Forecasting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** For some reason, you might see errors such as\n",
    "```\n",
    "RuntimeError: DataLoader worker (pid 1730479) is killed by signal: Aborted.\n",
    "```\n",
    "when running some of these cells (really only ones that loop over a DataLoader object). I'm not sure why this happens... it might relate to keyboard interrupting a multiprocessing call? Thankfully, (1) restarting the kernel will fix it, and (2) running this code in a script works without issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import trajectron.visualization as visualization\n",
    "import trajdata.visualization.vis as trajdata_vis\n",
    "\n",
    "from torch import optim, nn\n",
    "from torch.utils import data\n",
    "from tqdm.notebook import tqdm\n",
    "from trajectron.model.model_registrar import ModelRegistrar\n",
    "from trajectron.model.model_utils import UpdateMode\n",
    "from trajectron.model.trajectron import Trajectron\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from typing import DefaultDict, Dict, Final, List, Optional, Union\n",
    "from trajdata import UnifiedDataset, AgentType, AgentBatch\n",
    "\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this to suit your computing environment and folder structure!\n",
    "\n",
    "TRAJDATA_CACHE_DIR: Final[str] = \"/home/bivanovic/.unified_data_cache\"\n",
    "ETH_UCY_RAW_DATA_DIR: Final[str] = \"/home/bivanovic/datasets/eth_ucy_peds\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "AXHLINE_COLORS = {\n",
    "    \"Base\": \"#DD9787\",\n",
    "    \"K0\": \"#A6C48A\",\n",
    "    \"Oracle\": \"#BCB6FF\"\n",
    "}\n",
    "\n",
    "SEABORN_PALETTE = {\n",
    "    \"Finetune\": \"#AA7C85\",\n",
    "    \"K0+Finetune\": \"#2D93AD\",\n",
    "    \"Ours\": \"#67934D\",\n",
    "    \n",
    "    \"Base\": \"#DD9787\",\n",
    "    \"K0\": \"#A6C48A\",\n",
    "    \"Oracle\": \"#BCB6FF\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_dir: str, device: str, epoch: int = 10, custom_hyperparams: Optional[Dict] = None):\n",
    "    while epoch > 0:\n",
    "        save_path = Path(model_dir) / f'model_registrar-{epoch}.pt'\n",
    "        if save_path.is_file():\n",
    "            break\n",
    "        epoch -= 1\n",
    "\n",
    "    model_registrar = ModelRegistrar(model_dir, device)\n",
    "    with open(os.path.join(model_dir, 'config.json'), 'r') as config_json:\n",
    "        hyperparams = json.load(config_json)\n",
    "        \n",
    "    if custom_hyperparams is not None:\n",
    "        hyperparams.update(custom_hyperparams)\n",
    "\n",
    "    trajectron = Trajectron(model_registrar, hyperparams, None, device)\n",
    "    trajectron.set_environment()\n",
    "    trajectron.set_annealing_params()\n",
    "\n",
    "    checkpoint = torch.load(save_path, map_location=device)\n",
    "    trajectron.load_state_dict(checkpoint[\"model_state_dict\"], strict=False)\n",
    "\n",
    "    return trajectron, hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda:0'\n",
    "    torch.cuda.set_device(0)\n",
    "else:\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune_update(model: Trajectron, batch: AgentBatch = None, dataloader: data.DataLoader = None, num_epochs: int = None, update_mode: UpdateMode = UpdateMode.NO_UPDATE) -> float:\n",
    "    if batch is None and dataloader is None:\n",
    "        raise ValueError(\"Only one of batch or dataloader can be passed in.\")\n",
    "    \n",
    "    if dataloader is not None and num_epochs is None:\n",
    "        raise ValueError(\"num_epochs must not be None if dataloader is not None.\")\n",
    "    \n",
    "    lr_scheduler = None\n",
    "    optimizer = optim.Adam([{'params': model.model_registrar.get_all_but_name_match('map_encoder').parameters()},\n",
    "                            {'params': model.model_registrar.get_name_match('map_encoder').parameters(),\n",
    "                             'lr': model.hyperparams['map_enc_learning_rate']/10}],\n",
    "                           lr=model.hyperparams['learning_rate']/10)\n",
    "    # Set Learning Rate\n",
    "    if model.hyperparams['learning_rate_style'] == 'const':\n",
    "        lr_scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=1.0)\n",
    "    elif model.hyperparams['learning_rate_style'] == 'exp':\n",
    "        lr_scheduler = optim.lr_scheduler.ExponentialLR(optimizer,\n",
    "                                                        gamma=model.hyperparams['learning_decay_rate'])\n",
    "    \n",
    "    if batch is not None:\n",
    "        model.step_annealers()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        train_loss = model(batch, update_mode=update_mode)\n",
    "        train_loss.backward()\n",
    "\n",
    "        # Clipping gradients.\n",
    "        if model.hyperparams['grad_clip'] is not None:\n",
    "            nn.utils.clip_grad_value_(model.model_registrar.parameters(), model.hyperparams['grad_clip'])\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        # Stepping forward the learning rate scheduler and annealers.\n",
    "        lr_scheduler.step()\n",
    "    \n",
    "    elif dataloader is not None:\n",
    "        batch: AgentBatch\n",
    "        for batch_idx, batch in enumerate(dataloader):\n",
    "            model.step_annealers()\n",
    "            \n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            train_loss = model(batch)\n",
    "                        \n",
    "            train_loss.backward()\n",
    "\n",
    "            # Clipping gradients.\n",
    "            if model.hyperparams['grad_clip'] is not None:\n",
    "                nn.utils.clip_grad_value_(model.model_registrar.parameters(), model.hyperparams['grad_clip'])\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            # Stepping forward the learning rate scheduler and annealers.\n",
    "            lr_scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune_last_layer_update(model: Trajectron, batch: AgentBatch = None, dataloader: data.DataLoader = None, num_epochs: int = None) -> float:\n",
    "    if batch is None and dataloader is None:\n",
    "        raise ValueError(\"Only one of batch or dataloader can be passed in.\")\n",
    "    \n",
    "    if dataloader is not None and num_epochs is None:\n",
    "        raise ValueError(\"num_epochs must not be None if dataloader is not None.\")\n",
    "    \n",
    "    lr_scheduler = None\n",
    "    optimizer = optim.Adam([{'params': model.model_registrar.get_all_but_name_match('last_layer').parameters()},\n",
    "                            {'params': model.model_registrar.get_name_match('last_layer').parameters(),\n",
    "                             'lr': model.hyperparams['learning_rate']/10}],\n",
    "                           lr=0)\n",
    "    # Set Learning Rate\n",
    "    if model.hyperparams['learning_rate_style'] == 'const':\n",
    "        lr_scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=1.0)\n",
    "    elif model.hyperparams['learning_rate_style'] == 'exp':\n",
    "        lr_scheduler = optim.lr_scheduler.ExponentialLR(optimizer,\n",
    "                                                        gamma=model.hyperparams['learning_decay_rate'])\n",
    "    \n",
    "    if batch is not None:\n",
    "        model.step_annealers()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        train_loss = model(batch)\n",
    "        train_loss.backward()\n",
    "\n",
    "        # Clipping gradients.\n",
    "        if model.hyperparams['grad_clip'] is not None:\n",
    "            nn.utils.clip_grad_value_(model.model_registrar.parameters(), model.hyperparams['grad_clip'])\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        # Stepping forward the learning rate scheduler and annealers.\n",
    "        lr_scheduler.step()\n",
    "            \n",
    "    elif dataloader is not None:\n",
    "        batch: AgentBatch\n",
    "        for batch_idx, batch in enumerate(dataloader):\n",
    "            model.step_annealers()\n",
    "            \n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            train_loss = model(batch)\n",
    "                        \n",
    "            train_loss.backward()\n",
    "\n",
    "            # Clipping gradients.\n",
    "            if model.hyperparams['grad_clip'] is not None:\n",
    "                nn.utils.clip_grad_value_(model.model_registrar.parameters(), model.hyperparams['grad_clip'])\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            # Stepping forward the learning rate scheduler and annealers.\n",
    "            lr_scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for matched scene tags: ['eupeds_hotel-test_loo']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Agent Data (Serially): 100%|██████████| 1/1 [00:00<00:00, 8594.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 scenes in the scene index.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Agent Data Index (Serially): 100%|██████████| 1/1 [00:00<00:00, 197.93it/s]\n",
      "Structuring Agent Data Index: 100%|██████████| 1/1 [00:00<00:00, 2246.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for matched scene tags: ['eupeds_hotel-test_loo']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating Agent Data (Serially): 100%|██████████| 1/1 [00:00<00:00, 15534.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 scenes in the scene index.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Agent Data Index (Serially): 100%|██████████| 1/1 [00:00<00:00, 321.70it/s]\n",
      "Structuring Agent Data Index: 100%|██████████| 1/1 [00:00<00:00, 2355.03it/s]\n"
     ]
    }
   ],
   "source": [
    "peds_datasets = [\"eth\", \"hotel\", \"univ\", \"zara1\", \"zara2\"]\n",
    "\n",
    "history_sec = 2.8\n",
    "prediction_sec = 4.8\n",
    "\n",
    "base_checkpoint = 5\n",
    "k0_checkpoint = 4\n",
    "adaptive_checkpoint = 5\n",
    "oracle_checkpoint = 5\n",
    "\n",
    "train_scene = \"zara1\"\n",
    "eval_scene = \"hotel\"\n",
    "\n",
    "base_model = glob.glob(f\"kf_models/{train_scene}_*_base_*\")[0]\n",
    "k0_model = glob.glob(f\"kf_models/{train_scene}_*_k0_*\")[0]\n",
    "adaptive_model = glob.glob(f\"kf_models/{train_scene}_*_adaptive_*\")[0]\n",
    "oracle_model = glob.glob(f\"kf_models/{eval_scene}_*_base_*\")[0]\n",
    "\n",
    "eval_dataset = f\"eupeds_{eval_scene}\"\n",
    "eval_data = f\"{eval_dataset}-test_loo\"\n",
    "\n",
    "adaptive_trajectron, hyperparams = load_model(adaptive_model, device, epoch=adaptive_checkpoint,\n",
    "    custom_hyperparams={\"trajdata_cache_dir\": TRAJDATA_CACHE_DIR,\n",
    "                        \"single_mode_multi_sample\": False}\n",
    ")\n",
    "\n",
    "k0_trajectron, _ = load_model(k0_model, device, epoch=k0_checkpoint,\n",
    "    custom_hyperparams={\"trajdata_cache_dir\": TRAJDATA_CACHE_DIR,\n",
    "                        \"single_mode_multi_sample\": False}\n",
    ")\n",
    "k0_finetune_trajectron, _ = load_model(k0_model, device, epoch=k0_checkpoint,\n",
    "    custom_hyperparams={\"trajdata_cache_dir\": TRAJDATA_CACHE_DIR,\n",
    "                        \"single_mode_multi_sample\": False}\n",
    ")\n",
    "\n",
    "base_trajectron, _ = load_model(base_model, device, epoch=base_checkpoint,\n",
    "    custom_hyperparams={\"trajdata_cache_dir\": TRAJDATA_CACHE_DIR,\n",
    "                        \"single_mode_multi_sample\": False}\n",
    ")\n",
    "finetune_trajectron, _ = load_model(base_model, device, epoch=base_checkpoint,\n",
    "    custom_hyperparams={\"trajdata_cache_dir\": TRAJDATA_CACHE_DIR,\n",
    "                        \"single_mode_multi_sample\": False}\n",
    ")\n",
    "\n",
    "oracle_trajectron, _ = load_model(oracle_model, device, epoch=oracle_checkpoint,\n",
    "    custom_hyperparams={\"trajdata_cache_dir\": TRAJDATA_CACHE_DIR,\n",
    "                        \"single_mode_multi_sample\": False}\n",
    ")\n",
    "\n",
    "# Load training and evaluation environments and scenes\n",
    "attention_radius = defaultdict(lambda: 20.0) # Default range is 20m unless otherwise specified.\n",
    "attention_radius[(AgentType.PEDESTRIAN, AgentType.PEDESTRIAN)] = 10.0\n",
    "attention_radius[(AgentType.PEDESTRIAN, AgentType.VEHICLE)] = 20.0\n",
    "attention_radius[(AgentType.VEHICLE, AgentType.PEDESTRIAN)] = 20.0\n",
    "attention_radius[(AgentType.VEHICLE, AgentType.VEHICLE)] = 30.0\n",
    "\n",
    "online_eval_dataset = UnifiedDataset(\n",
    "    desired_data=[eval_data],\n",
    "    history_sec=(0.1, history_sec),\n",
    "    future_sec=(prediction_sec, prediction_sec),\n",
    "    agent_interaction_distances=attention_radius,\n",
    "    incl_robot_future=False,\n",
    "    incl_raster_map=False,\n",
    "    only_predict=[AgentType.PEDESTRIAN],\n",
    "    no_types=[AgentType.UNKNOWN],\n",
    "    num_workers=0,\n",
    "    cache_location=TRAJDATA_CACHE_DIR,\n",
    "    data_dirs={\n",
    "        eval_dataset: ETH_UCY_RAW_DATA_DIR,\n",
    "    },\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "batch_eval_dataset = UnifiedDataset(\n",
    "    desired_data=[eval_data],\n",
    "    history_sec=(history_sec, history_sec),\n",
    "    future_sec=(prediction_sec, prediction_sec),\n",
    "    agent_interaction_distances=attention_radius,\n",
    "    incl_robot_future=False,\n",
    "    incl_raster_map=False,\n",
    "    only_predict=[AgentType.PEDESTRIAN],\n",
    "    no_types=[AgentType.UNKNOWN],\n",
    "    num_workers=0,\n",
    "    cache_location=TRAJDATA_CACHE_DIR,\n",
    "    data_dirs={\n",
    "        eval_dataset: ETH_UCY_RAW_DATA_DIR,\n",
    "    },\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prog = re.compile(\"(.*)/(?P<scene_name>.*)/(.*)$\")\n",
    "\n",
    "def plot_outputs(\n",
    "    eval_dataset: UnifiedDataset,\n",
    "    dataset_idx: int,\n",
    "    model: Trajectron,\n",
    "    model_name: str,\n",
    "    agent_ts: int,\n",
    "    save=True,\n",
    "    extra_str=None,\n",
    "    subfolder=\"\",\n",
    "    filetype=\"png\"\n",
    "):\n",
    "    batch: AgentBatch = eval_dataset.get_collate_fn(pad_format=\"right\")([eval_dataset[dataset_idx]])\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    trajdata_vis.plot_agent_batch(batch, batch_idx=0, ax=ax, show=False, close=False)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # predictions = model.predict(batch,\n",
    "        #                             z_mode=True,\n",
    "        #                             gmm_mode=True,\n",
    "        #                             full_dist=False,\n",
    "        #                             output_dists=False)\n",
    "        # prediction = next(iter(predictions.values()))\n",
    "        \n",
    "        pred_dists, _ = model.predict(batch,\n",
    "                                      z_mode=False,\n",
    "                                      gmm_mode=False,\n",
    "                                      full_dist=True,\n",
    "                                      output_dists=True)\n",
    "        # pred_dist = next(iter(pred_dists.values()))\n",
    "\n",
    "    visualization.visualize_distribution(ax, pred_dists, batch_idx=0)\n",
    "    \n",
    "    # batch_eval: Dict[str, torch.Tensor] = evaluation.compute_batch_statistics_pt(\n",
    "    #     batch.agent_fut[..., :2],\n",
    "    #     prediction_output_dict=torch.from_numpy(prediction),\n",
    "    #     y_dists=pred_dist\n",
    "    # )\n",
    "    \n",
    "    scene_info_path, _, scene_ts = eval_dataset._data_index[dataset_idx]\n",
    "    scene_name = prog.match(scene_info_path).group(\"scene_name\")\n",
    "    \n",
    "    agent_name = batch.agent_name[0]\n",
    "    agent_type_name = f\"{str(AgentType(batch.agent_type[0].item()))}/{agent_name}\"\n",
    "    \n",
    "    ax.set_title(f\"{scene_name}/t={scene_ts} {agent_type_name}\")\n",
    "    # print(model_name, extra_str, batch_eval)\n",
    "    \n",
    "    if save:\n",
    "        fname = f\"plots/{subfolder}{model_name}_{scene_name}_{agent_name}_t{agent_ts}\"\n",
    "        if extra_str:\n",
    "            fname += \"_\" + extra_str\n",
    "        fig.savefig(fname + f\".{filetype}\")\n",
    "        \n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(\n",
    "    eval_dataset: UnifiedDataset,\n",
    "    batch_size: int = 128,\n",
    "    num_workers: int = 0,\n",
    "    shuffle: bool = False\n",
    "):\n",
    "    return data.DataLoader(\n",
    "        eval_dataset,\n",
    "        collate_fn=eval_dataset.get_collate_fn(pad_format=\"right\"),\n",
    "        pin_memory=False if device == 'cpu' else True,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=num_workers\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_list = [\"ml_ade\", \"ml_fde\", \"nll_mean\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Qualitative Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_outputs(batch_eval_dataset, 200, base_trajectron, \"Base\", -1, subfolder=f\"{train_scene}2{eval_scene}_\", filetype=\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_outputs(batch_eval_dataset, 200, k0_trajectron, \"K0\", -1, subfolder=f\"{train_scene}2{eval_scene}_\", filetype=\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_outputs(batch_eval_dataset, 200, oracle_trajectron, \"Oracle\", -1, subfolder=f\"{train_scene}2{eval_scene}_\", filetype=\"pdf\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Offline Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_results_to_summary(\n",
    "    model_name: str,\n",
    "    overall_summary_dict: Dict[str, List[float]],\n",
    "    model_perf_dict: Dict[AgentType, Dict[str, np.ndarray]]\n",
    "):\n",
    "    overall_summary_dict[\"model\"].append(model_name)\n",
    "    for metric in metrics_list:\n",
    "        overall_summary_dict[metric].append(np.concatenate(model_perf_dict[AgentType.PEDESTRIAN][metric]).mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004558086395263672,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 57,
       "postfix": null,
       "prefix": "Eval Base",
       "rate": null,
       "total": 10,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "028ea1fadc594373aa78490e4c151d37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval Base:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00628352165222168,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 57,
       "postfix": null,
       "prefix": "Eval K0",
       "rate": null,
       "total": 19,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad209a61fee64b7cb531c50673159bc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval K0:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00642704963684082,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 57,
       "postfix": null,
       "prefix": "Eval Oracle",
       "rate": null,
       "total": 10,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e034a96a10a4614bd80c6178870da3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval Oracle:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_dict = defaultdict(list)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Base Model\n",
    "    batch_eval_dataloader = get_dataloader(batch_eval_dataset, num_workers=16)\n",
    "    model_perf = defaultdict(lambda: defaultdict(list))\n",
    "    for eval_batch in tqdm(batch_eval_dataloader, desc=f'Eval Base'):\n",
    "        eval_results: Dict[AgentType, Dict[str, torch.Tensor]] = base_trajectron.predict_and_evaluate_batch(eval_batch)\n",
    "        for agent_type, metric_dict in eval_results.items():\n",
    "            for metric, values in metric_dict.items():\n",
    "                model_perf[agent_type][metric].append(values.cpu().numpy())\n",
    "\n",
    "    add_results_to_summary(\"Base\", eval_dict, model_perf)\n",
    "\n",
    "    # K0 Model\n",
    "    batch_eval_dataloader = get_dataloader(batch_eval_dataset, batch_size=64, num_workers=8)\n",
    "    model_perf = defaultdict(lambda: defaultdict(list))\n",
    "    for eval_batch in tqdm(batch_eval_dataloader, desc=f'Eval K0'):\n",
    "        eval_results: Dict[AgentType, Dict[str, torch.Tensor]] = k0_trajectron.predict_and_evaluate_batch(eval_batch)\n",
    "        for agent_type, metric_dict in eval_results.items():\n",
    "            for metric, values in metric_dict.items():\n",
    "                model_perf[agent_type][metric].append(values.cpu().numpy())\n",
    "\n",
    "    add_results_to_summary(\"K0\", eval_dict, model_perf)\n",
    "\n",
    "    # Oracle Model\n",
    "    batch_eval_dataloader = get_dataloader(batch_eval_dataset, num_workers=8)\n",
    "    model_perf = defaultdict(lambda: defaultdict(list))\n",
    "    for eval_batch in tqdm(batch_eval_dataloader, desc=f'Eval Oracle'):\n",
    "        eval_results: Dict[AgentType, Dict[str, torch.Tensor]] = oracle_trajectron.predict_and_evaluate_batch(eval_batch)\n",
    "        for agent_type, metric_dict in eval_results.items():\n",
    "            for metric, values in metric_dict.items():\n",
    "                model_perf[agent_type][metric].append(values.cpu().numpy())\n",
    "\n",
    "    add_results_to_summary(\"Oracle\", eval_dict, model_perf)\n",
    "\n",
    "    del eval_batch\n",
    "    del eval_results\n",
    "    del model_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'model': ['Base', 'K0', 'Oracle'],\n",
       "             'ml_ade': [1.2194594144821167,\n",
       "              0.556362509727478,\n",
       "              0.26388293504714966],\n",
       "             'ml_fde': [2.1753852367401123,\n",
       "              0.9837729930877686,\n",
       "              0.4870647192001343],\n",
       "             'nll_mean': [2.1622304916381836,\n",
       "              1.4858183860778809,\n",
       "              -0.6810566782951355]})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"results/{train_scene}2{eval_scene}_model_performance.pkl\", 'wb') as f:\n",
    "    pickle.dump(eval_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"results/{train_scene}2{eval_scene}_model_performance.pkl\", 'rb') as f:\n",
    "    eval_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'model': ['Base', 'K0', 'Oracle'],\n",
       "             'ml_ade': [1.2194594144821167,\n",
       "              0.556362509727478,\n",
       "              0.26388293504714966],\n",
       "             'ml_fde': [2.1753852367401123,\n",
       "              0.9837729930877686,\n",
       "              0.4870647192001343],\n",
       "             'nll_mean': [2.1622304916381836,\n",
       "              1.4858183860778809,\n",
       "              -0.6810566782951355]})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dataset2Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_results_to_summary(\n",
    "    model_name: str,\n",
    "    scene_from: str,\n",
    "    scene_to: str,\n",
    "    overall_summary_dict: Dict[str, List[float]],\n",
    "    model_perf_dict: Dict[AgentType, Dict[str, np.ndarray]]\n",
    "):\n",
    "    overall_summary_dict[\"model\"].append(model_name)\n",
    "    overall_summary_dict[\"scene_from\"].append(scene_from)\n",
    "    overall_summary_dict[\"scene_to\"].append(scene_to)\n",
    "    for metric in [\"ml_ade\", \"ml_fde\"]:\n",
    "        overall_summary_dict[metric].append(np.concatenate(model_perf_dict[AgentType.PEDESTRIAN][metric]).mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "peds_datasets = [\"eth\", \"hotel\", \"univ\", \"zara1\", \"zara2\"]\n",
    "\n",
    "eval_dict = defaultdict(list)\n",
    "\n",
    "eval_dict[\"model\"] = [\"T-GNN\"] * 20\n",
    "for train_scene in peds_datasets:\n",
    "    for eval_scene in [ds for ds in peds_datasets if ds != train_scene]:\n",
    "        eval_dict[\"scene_from\"].append(train_scene)\n",
    "        eval_dict[\"scene_to\"].append(eval_scene)\n",
    "\n",
    "# From T-GNN paper: https://arxiv.org/abs/2203.05046\n",
    "eval_dict[\"ml_ade\"].extend([1.13, 1.25, 0.94, 1.03, 2.54, 1.08, 2.25, 1.41, 0.97, 0.54, 0.61, 0.23, 0.88, 0.78, 0.59, 0.32, 0.87, 0.72, 0.65, 0.34])\n",
    "eval_dict[\"ml_fde\"].extend([2.18, 2.25, 1.78, 1.84, 4.15, 1.82, 4.04, 2.53, 1.91, 1.12, 1.30, 0.87, 1.92, 1.46, 1.25, 0.65, 1.86, 1.45, 1.28, 0.72])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eth -> hotel\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004253864288330078,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 57,
       "postfix": null,
       "prefix": "Eval",
       "rate": null,
       "total": 5,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eth -> univ\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0042095184326171875,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 57,
       "postfix": null,
       "prefix": "Eval",
       "rate": null,
       "total": 96,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eth -> zara1\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004056453704833984,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 57,
       "postfix": null,
       "prefix": "Eval",
       "rate": null,
       "total": 10,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eth -> zara2\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.006528377532958984,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 57,
       "postfix": null,
       "prefix": "Eval",
       "rate": null,
       "total": 24,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hotel -> eth\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004106998443603516,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 57,
       "postfix": null,
       "prefix": "Eval",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hotel -> univ\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004041910171508789,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 57,
       "postfix": null,
       "prefix": "Eval",
       "rate": null,
       "total": 96,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hotel -> zara1\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0041370391845703125,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 57,
       "postfix": null,
       "prefix": "Eval",
       "rate": null,
       "total": 10,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hotel -> zara2\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004006147384643555,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 57,
       "postfix": null,
       "prefix": "Eval",
       "rate": null,
       "total": 24,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "univ -> eth\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004050731658935547,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 57,
       "postfix": null,
       "prefix": "Eval",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "univ -> hotel\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004007816314697266,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 57,
       "postfix": null,
       "prefix": "Eval",
       "rate": null,
       "total": 5,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "univ -> zara1\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00399017333984375,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 57,
       "postfix": null,
       "prefix": "Eval",
       "rate": null,
       "total": 10,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "univ -> zara2\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004941463470458984,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 57,
       "postfix": null,
       "prefix": "Eval",
       "rate": null,
       "total": 24,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zara1 -> eth\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004024982452392578,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 57,
       "postfix": null,
       "prefix": "Eval",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zara1 -> hotel\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.003968477249145508,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 57,
       "postfix": null,
       "prefix": "Eval",
       "rate": null,
       "total": 5,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zara1 -> univ\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.003957271575927734,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 57,
       "postfix": null,
       "prefix": "Eval",
       "rate": null,
       "total": 96,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zara1 -> zara2\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004064798355102539,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 57,
       "postfix": null,
       "prefix": "Eval",
       "rate": null,
       "total": 24,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zara2 -> eth\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00400233268737793,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 57,
       "postfix": null,
       "prefix": "Eval",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zara2 -> hotel\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004004478454589844,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 57,
       "postfix": null,
       "prefix": "Eval",
       "rate": null,
       "total": 5,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zara2 -> univ\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.003928661346435547,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 57,
       "postfix": null,
       "prefix": "Eval",
       "rate": null,
       "total": 96,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zara2 -> zara1\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004046440124511719,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 57,
       "postfix": null,
       "prefix": "Eval",
       "rate": null,
       "total": 10,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_sec = 2.8\n",
    "prediction_sec = 4.8\n",
    "\n",
    "base_checkpoint = 5\n",
    "k0_checkpoint = 5\n",
    "adaptive_checkpoint = 5\n",
    "oracle_checkpoint = 5\n",
    "\n",
    "attention_radius = defaultdict(lambda: 20.0) # Default range is 20m unless otherwise specified.\n",
    "attention_radius[(AgentType.PEDESTRIAN, AgentType.PEDESTRIAN)] = 10.0\n",
    "attention_radius[(AgentType.PEDESTRIAN, AgentType.VEHICLE)] = 20.0\n",
    "attention_radius[(AgentType.VEHICLE, AgentType.PEDESTRIAN)] = 20.0\n",
    "attention_radius[(AgentType.VEHICLE, AgentType.VEHICLE)] = 30.0\n",
    "\n",
    "for train_scene in peds_datasets:\n",
    "    for eval_scene in [ds for ds in peds_datasets if ds != train_scene]:\n",
    "        print(train_scene, \"->\", eval_scene)\n",
    "        \n",
    "        k0_model = glob.glob(f\"kf_models/{train_scene}_*_k0_*\")[0]\n",
    "        adaptive_model = glob.glob(f\"kf_models/{train_scene}_*_adaptive_*\")[0]\n",
    "\n",
    "        adaptive_trajectron, hyperparams = load_model(adaptive_model, device, epoch=adaptive_checkpoint,\n",
    "            custom_hyperparams={\"trajdata_cache_dir\": TRAJDATA_CACHE_DIR,\n",
    "                                \"single_mode_multi_sample\": False}\n",
    "        )\n",
    "        k0_trajectron, _ = load_model(k0_model, device, epoch=k0_checkpoint,\n",
    "            custom_hyperparams={\"trajdata_cache_dir\": TRAJDATA_CACHE_DIR,\n",
    "                                \"single_mode_multi_sample\": False}\n",
    "        )\n",
    "\n",
    "        eval_dataset = f\"eupeds_{eval_scene}\"\n",
    "        eval_data = f\"eupeds_{eval_scene}-test_loo\"\n",
    "\n",
    "        batch_eval_dataset = UnifiedDataset(\n",
    "            desired_data=[eval_data],\n",
    "            history_sec=(history_sec, history_sec),\n",
    "            future_sec=(prediction_sec, prediction_sec),\n",
    "            agent_interaction_distances=attention_radius,\n",
    "            incl_robot_future=False,\n",
    "            incl_raster_map=False,\n",
    "            only_predict=[AgentType.PEDESTRIAN],\n",
    "            no_types=[AgentType.UNKNOWN],\n",
    "            num_workers=0,\n",
    "            cache_location=TRAJDATA_CACHE_DIR,\n",
    "            data_dirs={\n",
    "                eval_dataset: ETH_UCY_RAW_DATA_DIR,\n",
    "            },\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            batch_eval_dataloader = get_dataloader(batch_eval_dataset, batch_size=256, num_workers=8)\n",
    "            k0_model_perf = defaultdict(lambda: defaultdict(list))\n",
    "            adaptive_model_perf = defaultdict(lambda: defaultdict(list))\n",
    "            for eval_batch in tqdm(batch_eval_dataloader, desc=f'Eval', leave=False):\n",
    "                k0_eval_results: Dict[AgentType, Dict[str, torch.Tensor]] = k0_trajectron.predict_and_evaluate_batch(eval_batch)\n",
    "                adaptive_eval_results: Dict[AgentType, Dict[str, torch.Tensor]] = adaptive_trajectron.predict_and_evaluate_batch(\n",
    "                    eval_batch,\n",
    "                    update_mode=UpdateMode.BATCH_FROM_PRIOR\n",
    "                )\n",
    "\n",
    "                for agent_type, metric_dict in k0_eval_results.items():\n",
    "                    for metric, values in metric_dict.items():\n",
    "                        k0_model_perf[agent_type][metric].append(values.cpu().numpy())\n",
    "\n",
    "                for agent_type, metric_dict in adaptive_eval_results.items():\n",
    "                    for metric, values in metric_dict.items():\n",
    "                        adaptive_model_perf[agent_type][metric].append(values.cpu().numpy())\n",
    "\n",
    "            add_results_to_summary(\"K0\", train_scene, eval_scene, eval_dict, k0_model_perf)\n",
    "            add_results_to_summary(\"Ours\", train_scene, eval_scene, eval_dict, adaptive_model_perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>scene_from</th>\n",
       "      <th>scene_to</th>\n",
       "      <th>ml_ade</th>\n",
       "      <th>ml_fde</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T-GNN</td>\n",
       "      <td>eth</td>\n",
       "      <td>hotel</td>\n",
       "      <td>1.13</td>\n",
       "      <td>2.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T-GNN</td>\n",
       "      <td>eth</td>\n",
       "      <td>univ</td>\n",
       "      <td>1.25</td>\n",
       "      <td>2.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T-GNN</td>\n",
       "      <td>eth</td>\n",
       "      <td>zara1</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T-GNN</td>\n",
       "      <td>eth</td>\n",
       "      <td>zara2</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T-GNN</td>\n",
       "      <td>hotel</td>\n",
       "      <td>eth</td>\n",
       "      <td>2.54</td>\n",
       "      <td>4.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model scene_from scene_to  ml_ade  ml_fde\n",
       "0  T-GNN        eth    hotel    1.13    2.18\n",
       "1  T-GNN        eth     univ    1.25    2.25\n",
       "2  T-GNN        eth    zara1    0.94    1.78\n",
       "3  T-GNN        eth    zara2    1.03    1.84\n",
       "4  T-GNN      hotel      eth    2.54    4.15"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df = pd.DataFrame.from_dict(eval_dict)\n",
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>scene_from</th>\n",
       "      <th>scene_to</th>\n",
       "      <th>ml_ade</th>\n",
       "      <th>ml_fde</th>\n",
       "      <th>scene_from_to</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T-GNN</td>\n",
       "      <td>eth</td>\n",
       "      <td>hotel</td>\n",
       "      <td>1.13</td>\n",
       "      <td>2.18</td>\n",
       "      <td>eth -&gt; hotel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T-GNN</td>\n",
       "      <td>eth</td>\n",
       "      <td>univ</td>\n",
       "      <td>1.25</td>\n",
       "      <td>2.25</td>\n",
       "      <td>eth -&gt; univ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T-GNN</td>\n",
       "      <td>eth</td>\n",
       "      <td>zara1</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.78</td>\n",
       "      <td>eth -&gt; zara1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T-GNN</td>\n",
       "      <td>eth</td>\n",
       "      <td>zara2</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.84</td>\n",
       "      <td>eth -&gt; zara2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T-GNN</td>\n",
       "      <td>hotel</td>\n",
       "      <td>eth</td>\n",
       "      <td>2.54</td>\n",
       "      <td>4.15</td>\n",
       "      <td>hotel -&gt; eth</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model scene_from scene_to  ml_ade  ml_fde scene_from_to\n",
       "0  T-GNN        eth    hotel    1.13    2.18  eth -> hotel\n",
       "1  T-GNN        eth     univ    1.25    2.25   eth -> univ\n",
       "2  T-GNN        eth    zara1    0.94    1.78  eth -> zara1\n",
       "3  T-GNN        eth    zara2    1.03    1.84  eth -> zara2\n",
       "4  T-GNN      hotel      eth    2.54    4.15  hotel -> eth"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df['scene_from_to'] = eval_df[\"scene_from\"] + \" -> \" + eval_df[\"scene_to\"]\n",
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric_name in [\"ml_ade\", \"ml_fde\"]:\n",
    "    fig, ax = plt.subplots(figsize=(30, 5))\n",
    "\n",
    "    sns.barplot(data=eval_df, x=\"scene_from_to\", y=metric_name, hue=\"model\")\n",
    "\n",
    "    fig.savefig(f\"results/kf_d2d_{metric_name}.pdf\", bbox_inches=\"tight\")\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df.to_csv(\"results/kf_d2d_evaluation.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Online (Per Agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_agent_eval(\n",
    "    curr_agent: str,\n",
    "    model: Trajectron,\n",
    "    model_name: str,\n",
    "    batch: AgentBatch,\n",
    "    agent_ts: int,\n",
    "    model_eval_dict: DefaultDict[str, Union[List[int], List[float]]],\n",
    "    plot=True\n",
    "):\n",
    "    with torch.no_grad():\n",
    "        if plot:\n",
    "            plot_outputs(online_eval_dataset,\n",
    "                         dataset_idx=batch.data_idx[0].item(),\n",
    "                         model=model,\n",
    "                         model_name=model_name,\n",
    "                         agent_ts=agent_ts,\n",
    "                         subfolder=f\"per_agent_{train_scene}2{eval_scene}/\")\n",
    "        \n",
    "        model_perf = defaultdict(lambda: defaultdict(list))\n",
    "        eval_results: Dict[AgentType, Dict[str, torch.Tensor]] = model.predict_and_evaluate_batch(batch)\n",
    "        for agent_type, metric_dict in eval_results.items():\n",
    "            for metric, values in metric_dict.items():\n",
    "                model_perf[agent_type][metric].append(values.cpu().numpy())\n",
    "\n",
    "        for idx, metric in enumerate(metrics_list):\n",
    "            if len(model_perf[AgentType.PEDESTRIAN]) == 0:\n",
    "                break\n",
    "            \n",
    "            metric_values = np.concatenate(model_perf[AgentType.PEDESTRIAN][metric]).tolist()\n",
    "            if idx == 0:\n",
    "                model_eval_dict[\"agent_ts\"].extend([agent_ts] * len(metric_values))\n",
    "\n",
    "            model_eval_dict[metric].extend(metric_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_time_eval(\n",
    "    curr_agent: str,\n",
    "    model: Trajectron,\n",
    "    model_name: str,\n",
    "    online_batch: AgentBatch,\n",
    "    model_eval_dict: DefaultDict[str, Union[List[int], List[float]]],\n",
    "    plot=True\n",
    "):\n",
    "    if plot:\n",
    "        plot_outputs(online_eval_dataset,\n",
    "                     dataset_idx=online_batch.data_idx[0].item(),\n",
    "                     model=model,\n",
    "                     model_name=model_name,\n",
    "                     agent_ts=0,\n",
    "                     subfolder=f\"per_agent_{train_scene}2{eval_scene}/\",\n",
    "                     extra_str=f\"init\")\n",
    "    per_agent_eval(curr_agent, model, model_name, online_batch, 0, model_eval_dict, plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_agent_s2s(\n",
    "    online_eval_dataset, adaptive_trajectron,\n",
    "    base_trajectron, k0_trajectron, oracle_trajectron,\n",
    "    base_model, base_checkpoint, k0_model, k0_checkpoint,\n",
    "    n_samples=3001\n",
    "):\n",
    "    adaptive_dict = defaultdict(list)\n",
    "    finetune_dict = defaultdict(list)\n",
    "    k0_finetune_dict = defaultdict(list)\n",
    "\n",
    "    base_dict = defaultdict(list)\n",
    "    k0_dict = defaultdict(list)\n",
    "    oracle_dict = defaultdict(list)\n",
    "\n",
    "    online_eval_dataloader = get_dataloader(online_eval_dataset, batch_size=1, num_workers=4, shuffle=False)\n",
    "\n",
    "    adaptive_trajectron.reset_adaptive_info()\n",
    "\n",
    "    outer_pbar = tqdm(\n",
    "        online_eval_dataloader,\n",
    "        total=min(n_samples, len(online_eval_dataloader)),\n",
    "        desc=f'Adaptive Eval PH={prediction_sec}',\n",
    "        position=0,\n",
    "    )\n",
    "\n",
    "    plot_per_step = False\n",
    "\n",
    "    curr_agent: str = None\n",
    "    agent_ts: int = 0\n",
    "    online_batch: AgentBatch\n",
    "    for data_sample, online_batch in enumerate(outer_pbar):\n",
    "        if data_sample >= n_samples:\n",
    "            outer_pbar.close()\n",
    "            break\n",
    "\n",
    "        if online_batch.agent_name[0] != curr_agent:\n",
    "            # Resetting the K_n, L_n for each Bayesian last layer.\n",
    "            adaptive_trajectron.reset_adaptive_info()\n",
    "\n",
    "            # Resetting the finetune baseline to its base.\n",
    "            finetune_trajectron, _ = load_model(base_model, device, epoch=base_checkpoint,\n",
    "                custom_hyperparams={\"trajdata_cache_dir\": TRAJDATA_CACHE_DIR,\n",
    "                                    \"single_mode_multi_sample\": False}\n",
    "            )\n",
    "            k0_finetune_trajectron, _ = load_model(k0_model, device, epoch=k0_checkpoint,\n",
    "                custom_hyperparams={\"trajdata_cache_dir\": TRAJDATA_CACHE_DIR,\n",
    "                                    \"single_mode_multi_sample\": False}\n",
    "            )\n",
    "\n",
    "            curr_agent = online_batch.agent_name[0]\n",
    "            agent_ts: int = 0\n",
    "\n",
    "#             init_time_eval(curr_agent, adaptive_trajectron, \"Ours\", online_batch, adaptive_dict, plot_per_step)\n",
    "#             init_time_eval(curr_agent, finetune_trajectron, \"Finetune\", online_batch, finetune_dict, plot_per_step)\n",
    "#             init_time_eval(curr_agent, k0_finetune_trajectron, \"K0+Finetune\", online_batch, k0_finetune_dict, plot_per_step)\n",
    "\n",
    "#             init_time_eval(curr_agent, base_trajectron, \"Base\", online_batch, base_dict, plot_per_step)\n",
    "#             init_time_eval(curr_agent, k0_trajectron, \"K0\", online_batch, k0_dict, plot_per_step)\n",
    "#             init_time_eval(curr_agent, oracle_trajectron, \"Oracle\", online_batch, oracle_dict, plot_per_step)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # This is the inference call that internally updates L_n and K_n.\n",
    "            adaptive_trajectron.adaptive_predict(\n",
    "                online_batch,\n",
    "                update_mode=UpdateMode.ITERATIVE\n",
    "            )\n",
    "\n",
    "        finetune_update(finetune_trajectron, online_batch)\n",
    "        finetune_last_layer_update(k0_finetune_trajectron, online_batch)\n",
    "\n",
    "        # # This is effectively measuring number of updates/observed data points.\n",
    "        # agent_ts += 1\n",
    "\n",
    "        if agent_ts % 10 == 0:\n",
    "            per_agent_eval(curr_agent, adaptive_trajectron, \"Ours\", online_batch, agent_ts, adaptive_dict, plot=plot_per_step)\n",
    "            per_agent_eval(curr_agent, finetune_trajectron, \"Finetune\", online_batch, agent_ts, finetune_dict, plot=plot_per_step)\n",
    "            per_agent_eval(curr_agent, k0_finetune_trajectron, \"K0+Finetune\", online_batch, agent_ts, k0_finetune_dict, plot=plot_per_step)\n",
    "\n",
    "            per_agent_eval(curr_agent, base_trajectron, \"Base\", online_batch, agent_ts, base_dict, plot=plot_per_step)\n",
    "            per_agent_eval(curr_agent, k0_trajectron, \"K0\", online_batch, agent_ts, k0_dict, plot=plot_per_step)\n",
    "            per_agent_eval(curr_agent, oracle_trajectron, \"Oracle\", online_batch, agent_ts, oracle_dict, plot=plot_per_step)\n",
    "\n",
    "        # This is effectively measuring the most-recently seen timestep.\n",
    "        agent_ts += 1\n",
    "        \n",
    "    return (\n",
    "        adaptive_dict, finetune_dict, k0_finetune_dict,\n",
    "        base_dict, k0_dict, oracle_dict\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zara1 -> hotel\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0038335323333740234,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 57,
       "postfix": null,
       "prefix": "Adaptive Eval PH=4.8",
       "rate": null,
       "total": 2312,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53a3e16f5309435185b1c635bbc044b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adaptive Eval PH=4.8:   0%|          | 0/2312 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_sec = 2.8\n",
    "prediction_sec = 4.8\n",
    "\n",
    "base_checkpoint = 5\n",
    "k0_checkpoint = 4\n",
    "adaptive_checkpoint = 5\n",
    "oracle_checkpoint = 5\n",
    "\n",
    "attention_radius = defaultdict(lambda: 20.0) # Default range is 20m unless otherwise specified.\n",
    "attention_radius[(AgentType.PEDESTRIAN, AgentType.PEDESTRIAN)] = 10.0\n",
    "attention_radius[(AgentType.PEDESTRIAN, AgentType.VEHICLE)] = 20.0\n",
    "attention_radius[(AgentType.VEHICLE, AgentType.PEDESTRIAN)] = 20.0\n",
    "attention_radius[(AgentType.VEHICLE, AgentType.VEHICLE)] = 30.0\n",
    "\n",
    "for train_scene in [\"zara1\"]:\n",
    "    for eval_scene in [\"hotel\"]:\n",
    "        print(train_scene, \"->\", eval_scene)\n",
    "        \n",
    "        base_model = glob.glob(f\"kf_models/{train_scene}_*_base_*\")[0]\n",
    "        k0_model = glob.glob(f\"kf_models/{train_scene}_*_k0_*\")[0]\n",
    "        adaptive_model = glob.glob(f\"kf_models/{train_scene}_*_adaptive_*\")[0]\n",
    "        oracle_model = glob.glob(f\"kf_models/{eval_scene}_*_base_*\")[0]\n",
    "\n",
    "        adaptive_trajectron, hyperparams = load_model(adaptive_model, device, epoch=adaptive_checkpoint,\n",
    "            custom_hyperparams={\"trajdata_cache_dir\": TRAJDATA_CACHE_DIR,\n",
    "                                \"single_mode_multi_sample\": False}\n",
    "        )\n",
    "        k0_trajectron, _ = load_model(k0_model, device, epoch=k0_checkpoint,\n",
    "            custom_hyperparams={\"trajdata_cache_dir\": TRAJDATA_CACHE_DIR,\n",
    "                                \"single_mode_multi_sample\": False}\n",
    "        )        \n",
    "        base_trajectron, _ = load_model(base_model, device, epoch=base_checkpoint,\n",
    "            custom_hyperparams={\"trajdata_cache_dir\": TRAJDATA_CACHE_DIR,\n",
    "                                \"single_mode_multi_sample\": False}\n",
    "        )\n",
    "        oracle_trajectron, _ = load_model(oracle_model, device, epoch=oracle_checkpoint,\n",
    "            custom_hyperparams={\"trajdata_cache_dir\": TRAJDATA_CACHE_DIR,\n",
    "                                \"single_mode_multi_sample\": False}\n",
    "        )\n",
    "\n",
    "        eval_dataset = f\"eupeds_{eval_scene}\"\n",
    "        eval_data = f\"eupeds_{eval_scene}-test_loo\"\n",
    "\n",
    "        online_eval_dataset = UnifiedDataset(\n",
    "            desired_data=[eval_data],\n",
    "            history_sec=(0.1, history_sec),\n",
    "            future_sec=(prediction_sec, prediction_sec),\n",
    "            agent_interaction_distances=attention_radius,\n",
    "            incl_robot_future=False,\n",
    "            incl_raster_map=False,\n",
    "            only_predict=[AgentType.PEDESTRIAN],\n",
    "            no_types=[AgentType.UNKNOWN],\n",
    "            num_workers=0,\n",
    "            cache_location=TRAJDATA_CACHE_DIR,\n",
    "            data_dirs={\n",
    "                eval_dataset: ETH_UCY_RAW_DATA_DIR,\n",
    "            },\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        batch_eval_dataset = UnifiedDataset(\n",
    "            desired_data=[eval_data],\n",
    "            history_sec=(history_sec, history_sec),\n",
    "            future_sec=(prediction_sec, prediction_sec),\n",
    "            agent_interaction_distances=attention_radius,\n",
    "            incl_robot_future=False,\n",
    "            incl_raster_map=False,\n",
    "            only_predict=[AgentType.PEDESTRIAN],\n",
    "            no_types=[AgentType.UNKNOWN],\n",
    "            num_workers=0,\n",
    "            cache_location=TRAJDATA_CACHE_DIR,\n",
    "            data_dirs={\n",
    "                eval_dataset: ETH_UCY_RAW_DATA_DIR,\n",
    "            },\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        (\n",
    "            adaptive_dict, finetune_dict, k0_finetune_dict,\n",
    "            base_dict, k0_dict, oracle_dict\n",
    "        ) = per_agent_s2s(\n",
    "            online_eval_dataset, adaptive_trajectron,\n",
    "            base_trajectron, k0_trajectron, oracle_trajectron,\n",
    "            base_model, base_checkpoint, k0_model, k0_checkpoint\n",
    "        )\n",
    "\n",
    "        adaptive_eval_df = pd.DataFrame.from_dict(adaptive_dict)\n",
    "        adaptive_eval_df[\"method\"] = \"Ours\"\n",
    "        finetune_eval_df = pd.DataFrame.from_dict(finetune_dict)\n",
    "        finetune_eval_df[\"method\"] = \"Finetune\"\n",
    "        k0_finetune_eval_df = pd.DataFrame.from_dict(k0_finetune_dict)\n",
    "        k0_finetune_eval_df[\"method\"] = \"K0+Finetune\"\n",
    "\n",
    "        base_eval_df = pd.DataFrame.from_dict(base_dict)\n",
    "        base_eval_df[\"method\"] = \"Base\"\n",
    "        k0_eval_df = pd.DataFrame.from_dict(k0_dict)\n",
    "        k0_eval_df[\"method\"] = \"K0\"\n",
    "        oracle_eval_df = pd.DataFrame.from_dict(oracle_dict)\n",
    "        oracle_eval_df[\"method\"] = \"Oracle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relativize_df(input_df, reference_df):\n",
    "    output_df = input_df.copy()\n",
    "    output_df.loc[:, metrics_list] = 100*(output_df.loc[:, metrics_list] - reference_df.loc[:, metrics_list])/reference_df.loc[:, metrics_list]\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as mtick\n",
    "\n",
    "combined_df = pd.concat((\n",
    "    relativize_df(adaptive_eval_df, base_eval_df),\n",
    "    relativize_df(finetune_eval_df, base_eval_df),\n",
    "    relativize_df(k0_finetune_eval_df, base_eval_df),\n",
    "    \n",
    "    relativize_df(k0_eval_df, base_eval_df),\n",
    "    relativize_df(base_eval_df, base_eval_df),\n",
    "    relativize_df(oracle_eval_df, base_eval_df)\n",
    "), ignore_index=True)\n",
    "\n",
    "combined_df.to_csv(f\"results/kf_{train_scene}2{eval_scene}_per_agent_online_rel.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Offline Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_calibration_values(model: Trajectron, dataloader: data.DataLoader):\n",
    "    est_probs = list()\n",
    "    \n",
    "    for batch in tqdm(dataloader, leave=False):\n",
    "        batch.to(model.device)\n",
    "        \n",
    "        node_type: AgentType\n",
    "        for node_type in batch.agent_types():\n",
    "            mgcvae = model.node_models_dict[node_type.name]\n",
    "\n",
    "            agent_type_batch = batch.for_agent_type(node_type)\n",
    "            ph = agent_type_batch.agent_fut.shape[1]\n",
    "\n",
    "            # Run forward pass\n",
    "            y_dists, _ = mgcvae.predict(agent_type_batch,\n",
    "                                        prediction_horizon=ph,\n",
    "                                        num_samples=1,\n",
    "                                        z_mode=False,\n",
    "                                        gmm_mode=False,\n",
    "                                        full_dist=True,\n",
    "                                        output_dists=True)\n",
    "            \n",
    "            estimated_prob = y_dists.quantile(batch.agent_fut[..., :2])\n",
    "            est_probs.extend(estimated_prob.flatten().tolist())\n",
    "            \n",
    "    return np.asarray(est_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "040db37470c4412b99ab18df5451087b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcf0b5231c89476580438a158f363253",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb705ac29a6341ec8d1be5cc4453472a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "calib_values = list()\n",
    "\n",
    "with torch.no_grad():\n",
    "    base_calib = compute_calibration_values(base_trajectron, get_dataloader(batch_eval_dataset, num_workers=16))\n",
    "\n",
    "    batch_dataloader = get_dataloader(batch_eval_dataset, num_workers=8)\n",
    "    k0_calib = compute_calibration_values(k0_trajectron, batch_dataloader)\n",
    "    oracle_calib = compute_calibration_values(oracle_trajectron, batch_dataloader)\n",
    "\n",
    "calib_values.append((0, base_calib, k0_calib, oracle_calib))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibration_plot(est_gt_probs: np.ndarray, method_name: str, ax):\n",
    "    thresholds = np.linspace(0, 1, 101)\n",
    "    \n",
    "    num_gt_points = est_gt_probs.shape[0]\n",
    "    # Commenting this out, although it could be used to scale to the max PDF height.\n",
    "    # No need though, without it we can see overconfidence easier.\n",
    "    # max_pdf = est_gt_probs.max()\n",
    "    \n",
    "    fraction_gt_included = [(est_gt_probs >= threshold).sum() / num_gt_points for threshold in thresholds]\n",
    "    \n",
    "    ax.plot(thresholds, fraction_gt_included, label=method_name, lw=3, c=SEABORN_PALETTE[method_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_calibration_plots(base_calib, k0_calib, oracle_calib, ours_calib, finetune_calib, k0_finetune_calib, num_updates):\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    ax.plot([0, 1], [1, 0], label=\"Ideal\", ls=\"--\", c=\"k\")\n",
    "\n",
    "    calibration_plot(base_calib, \"Base\", ax)\n",
    "    calibration_plot(k0_calib, \"K0\", ax)\n",
    "    calibration_plot(oracle_calib, \"Oracle\", ax)\n",
    "\n",
    "    calibration_plot(ours_calib, \"Ours\", ax)\n",
    "    calibration_plot(finetune_calib, \"Finetune\", ax)\n",
    "    calibration_plot(k0_finetune_calib, \"K0+Finetune\", ax)\n",
    "\n",
    "    ax.legend(bbox_to_anchor=(1.04, 0.5), loc=\"center left\", borderaxespad=0)\n",
    "    ax.set_xlabel(\"Probability Threshold\")\n",
    "    ax.set_ylabel(\"Fraction of GT Points\")\n",
    "\n",
    "    ax.grid(False)\n",
    "    \n",
    "    # fig.savefig(f\"results/{train_scene}2{eval_scene}_calibration_after{num_updates}.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58579c5390e340dea6cef3c7fd21144a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adaptive Eval PH=4.8:   0%|          | 0/2001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82bedbb5c4bc41ad8a4854b4fa7bc4a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b051b59cc4a744deabbdece52f9c8d2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0692b788d17b41ca8b9c0cb5dedf8e0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03d5f1e8c3ca4d9b95ce1488ed22a82d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07665ae34b854ac38ff7896abe73941a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b8f4b784fa44284b9c9595ee207e00f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc3b8680e2874cc28817af99796e2f9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2d65508505642488f1d181601989f2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd3840e4a62e448f8e660585648d5983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c899528b403c4f7896e62e98fc227de9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dc33a2f39964a18abf8698b1cd88455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df9fa741c1a14878b19e0ec891a2d421",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3424dc48ecd40be94468822f699c052",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05c59a7aee684ad88974d8a1ef197697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69f05d510a9749a8b1f64fd63d8a75d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98062910492648b5b3f6482892b85696",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21e192376f474f908630f01cd289adb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2633231403444f0d911c0b0f61cf3bac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f500e5719e4d42678faf0e7241b13efa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7247aa35189f4254b08d1b5fb1969573",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0242540da9b54578b9b4a51c06354838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88fdebd7b3f64e3f868ea8e5c0d3ea56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "671fee5078334b94b7e523d713120e73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a68405fcd69141379dbbfaab9c255d64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a91e4e7cd8b545b290dec1192ed79f77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6a0097a2a5148ab96b25a1ab39a6b21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14e8039939f24c4ab92ed7c9e1fd8573",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e837cfe8c8a54f439d37683e22951f3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be20f84187274676b9bf3da45a8ec7b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fd25c6a111f4f208549d9714321cee4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "273b2de7046e4bfb83af3d72ec246bde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4a2608756494a868207e56ec1785e40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e72d44289474300b531ce92d872a951",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ccf9c9487c742279c31a14b21eddb43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7209b40f23f5432fa845f2b3e7171d78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8d5cf6cc4b2450985d34671dfbca7aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d3f73ec24b74d22835d62fe443af95f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "742f478775fa483fa1368cbe3ebde064",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7e2e07542814f21975e343f78b22712",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d11aaf2b8ae34e3cbedaaacee3cdc307",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a752f4937da4f8a9f8deadd0cc91747",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5387b303d86b4b3f8e9f579cdbc3a2f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5764541f96b5491abc0da49f4ee4c8ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad070658828f4a72a203aa0c8b9e009c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83dabb87441749ff9e0e190d7ba81aac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82a508d04a0340ba90597a03f2900ef2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0340d763e4894751bf2575e13f4e01b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5632e7caf0044f2db0dd6aa79068176c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "239affe3df594fd995db9614e37477d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ea48538d0aa48e69bc46f72aadfd1a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56a0077fd5574ff580d799e884cadbd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3ac174ae6da4c4a8a5c9d608d3e651b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77db9315a70b4ccd91f32151ed45dc32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "693f46ee7ccc4c819973cfac58bc7445",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cdeca924e41451599191174152ce8c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "419598eaeffc4c8ea47071addcbf89e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec9dee4abf42453d92787876a999b9ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25de315e612f4a8db093d4dcee269af0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67247ab0194242438ebc179a5de4d674",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "281cd6acf4f84a419722f1ea6905cd7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4dfe3b043354cfc8fc6bd38a50bf152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3fd270c09b743de83c5eb644b304c11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74655b29ba104b3d94ef2fec29c01775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "online_eval_dataloader = get_dataloader(online_eval_dataset, batch_size=1, shuffle=True)\n",
    "batch_eval_dataloader = get_dataloader(batch_eval_dataset, num_workers=8)\n",
    "\n",
    "adaptive_trajectron.reset_adaptive_info()\n",
    "\n",
    "# Resetting the finetune baselines to their base.\n",
    "finetune_trajectron, _ = load_model(base_model, device, epoch=base_checkpoint,\n",
    "    custom_hyperparams={\"trajdata_cache_dir\": TRAJDATA_CACHE_DIR,\n",
    "                        \"single_mode_multi_sample\": False}\n",
    ")\n",
    "k0_finetune_trajectron, _ = load_model(k0_model, device, epoch=k0_checkpoint,\n",
    "    custom_hyperparams={\"trajdata_cache_dir\": TRAJDATA_CACHE_DIR,\n",
    "                        \"single_mode_multi_sample\": False}\n",
    ")\n",
    "\n",
    "N_SAMPLES = 2001\n",
    "\n",
    "outer_pbar = tqdm(\n",
    "    online_eval_dataloader,\n",
    "    total=min(N_SAMPLES, len(online_eval_dataloader)),\n",
    "    desc=f'Adaptive Eval PH={prediction_sec}',\n",
    "    position=0,\n",
    ")\n",
    "\n",
    "plot_per_eval = False\n",
    "\n",
    "online_batch: AgentBatch\n",
    "for data_sample, online_batch in enumerate(outer_pbar):\n",
    "    if data_sample >= N_SAMPLES:\n",
    "        outer_pbar.close()\n",
    "        break\n",
    "    \n",
    "    if data_sample == 0:\n",
    "        ours_calib = compute_calibration_values(adaptive_trajectron, batch_eval_dataloader)\n",
    "        finetune_calib = compute_calibration_values(finetune_trajectron, batch_eval_dataloader)\n",
    "        k0_finetune_calib = compute_calibration_values(k0_finetune_trajectron, batch_eval_dataloader)\n",
    "        \n",
    "        calib_values.append((data_sample, ours_calib, finetune_calib, k0_finetune_calib))\n",
    "            \n",
    "    with torch.no_grad():\n",
    "        # This is the inference call that internally updates L_n and K_n.\n",
    "        adaptive_trajectron.adaptive_predict(\n",
    "            online_batch,\n",
    "            update_mode=UpdateMode.ITERATIVE\n",
    "        )\n",
    "    \n",
    "    finetune_update(finetune_trajectron, online_batch)\n",
    "    finetune_last_layer_update(k0_finetune_trajectron, online_batch)\n",
    "    \n",
    "    if (data_sample + 1) % 100 == 0:    \n",
    "        ours_calib = compute_calibration_values(adaptive_trajectron, batch_eval_dataloader)\n",
    "        finetune_calib = compute_calibration_values(finetune_trajectron, batch_eval_dataloader)\n",
    "        k0_finetune_calib = compute_calibration_values(k0_finetune_trajectron, batch_eval_dataloader)\n",
    "        \n",
    "        calib_values.append((data_sample, ours_calib, finetune_calib, k0_finetune_calib))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"results/{train_scene}2{eval_scene}_model_calibration.pkl\", 'wb') as f:\n",
    "    pickle.dump(calib_values, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "899084b979ee3091ee6a50779e35f9060d5c7fcf44a81dbe99f3cee468cea24b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
