{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online Adaptive Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import trajdata.visualization.vis as trajdata_vis\n",
    "\n",
    "from torch.utils import data\n",
    "from tqdm.notebook import tqdm\n",
    "from trajectron.model.model_registrar import ModelRegistrar\n",
    "from trajectron.model.model_utils import UpdateMode\n",
    "from trajectron.model.trajectron import Trajectron\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from typing import DefaultDict, Dict, Final, List, Optional, Union\n",
    "from trajdata import UnifiedDataset, AgentType, AgentBatch\n",
    "\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this to suit your computing environment and folder structure!\n",
    "\n",
    "TRAJDATA_CACHE_DIR: Final[str] = \"/home/bivanovic/.unified_data_cache\"\n",
    "LYFT_SAMPLE_RAW_DATA_DIR: Final[str] = \"/home/bivanovic/datasets/lyft/scenes/sample.zarr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = \"models/nusc_mm_base_tpp-11_Sep_2022_19_15_45\"\n",
    "k0_model = \"models/nusc_mm_k0_tpp-12_Sep_2022_00_40_16\"\n",
    "adaptive_model = \"models/nusc_mm_sec4_tpp-13_Sep_2022_11_06_01\"\n",
    "oracle_model = \"models/lyft_mm_base_tpp-11_Sep_2022_18_56_49\"\n",
    "\n",
    "base_checkpoint = 20\n",
    "k0_checkpoint = 20\n",
    "adaptive_checkpoint = 20\n",
    "oracle_checkpoint = 1\n",
    "\n",
    "eval_data = \"lyft_sample-mini_val\"\n",
    "\n",
    "history_sec = 2.0\n",
    "prediction_sec = 6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "AXHLINE_COLORS = {\n",
    "    \"Base\": \"#DD9787\",\n",
    "    \"K0\": \"#A6C48A\",\n",
    "    \"Oracle\": \"#A2999E\"\n",
    "}\n",
    "\n",
    "SEABORN_PALETTE = {\n",
    "    \"Finetune\": \"#AA7C85\",\n",
    "    \"K0\": \"#A6C48A\",\n",
    "    \"Ours+Finetune\": \"#2D93AD\",\n",
    "    \"Ours\": \"#9F9FED\",\n",
    "    \"Base\": \"#DD9787\",\n",
    "    \"K0+Finetune\": \"#67934D\",\n",
    "    \"Oracle\": \"#A2999E\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_dir: str, device: str, epoch: int = 10, custom_hyperparams: Optional[Dict] = None):\n",
    "    save_path = Path(model_dir) / f'model_registrar-{epoch}.pt'\n",
    "\n",
    "    model_registrar = ModelRegistrar(model_dir, device)\n",
    "    with open(os.path.join(model_dir, 'config.json'), 'r') as config_json:\n",
    "        hyperparams = json.load(config_json)\n",
    "        \n",
    "    if custom_hyperparams is not None:\n",
    "        hyperparams.update(custom_hyperparams)\n",
    "\n",
    "    trajectron = Trajectron(model_registrar, hyperparams, None, device)\n",
    "    trajectron.set_environment()\n",
    "    trajectron.set_annealing_params()\n",
    "\n",
    "    checkpoint = torch.load(save_path, map_location=device)\n",
    "    trajectron.load_state_dict(checkpoint[\"model_state_dict\"], strict=False)\n",
    "\n",
    "    return trajectron, hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda:0'\n",
    "    torch.cuda.set_device(0)\n",
    "else:\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for matched scene tags: ['lyft_sample-palo_alto-mini_val']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Agent Data (Serially): 100%|██████████| 20/20 [00:00<00:00, 46811.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 scenes in the scene index.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Agent Data Index (Serially): 100%|██████████| 20/20 [00:00<00:00, 157.74it/s]\n",
      "Structuring Agent Data Index: 100%|██████████| 20/20 [00:00<00:00, 20590.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for matched scene tags: ['lyft_sample-palo_alto-mini_val']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating Agent Data (Serially): 100%|██████████| 20/20 [00:00<00:00, 47259.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 scenes in the scene index.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Agent Data Index (Serially): 100%|██████████| 20/20 [00:00<00:00, 633.05it/s]\n",
      "Structuring Agent Data Index: 100%|██████████| 20/20 [00:00<00:00, 26165.34it/s]\n"
     ]
    }
   ],
   "source": [
    "adaptive_trajectron, hyperparams = load_model(\n",
    "    adaptive_model, device, epoch=adaptive_checkpoint,\n",
    "    custom_hyperparams={\"trajdata_cache_dir\": TRAJDATA_CACHE_DIR,\n",
    "                        \"single_mode_multi_sample\": True}\n",
    ")\n",
    "\n",
    "# Load training and evaluation environments and scenes\n",
    "attention_radius = defaultdict(lambda: 20.0) # Default range is 20m unless otherwise specified.\n",
    "attention_radius[(AgentType.PEDESTRIAN, AgentType.PEDESTRIAN)] = 10.0\n",
    "attention_radius[(AgentType.PEDESTRIAN, AgentType.VEHICLE)] = 20.0\n",
    "attention_radius[(AgentType.VEHICLE, AgentType.PEDESTRIAN)] = 20.0\n",
    "attention_radius[(AgentType.VEHICLE, AgentType.VEHICLE)] = 30.0\n",
    "\n",
    "map_params = {\"px_per_m\": 2, \"map_size_px\": 100, \"offset_frac_xy\": (-0.75, 0.0)}\n",
    "\n",
    "online_eval_dataset = UnifiedDataset(\n",
    "    desired_data=[eval_data],\n",
    "    # desired_dt=0.5,\n",
    "    history_sec=(0.1, history_sec),\n",
    "    future_sec=(prediction_sec, prediction_sec),\n",
    "    agent_interaction_distances=attention_radius,\n",
    "    incl_robot_future=hyperparams['incl_robot_node'],\n",
    "    incl_map=hyperparams['map_encoding'],\n",
    "    map_params=map_params,\n",
    "    only_predict=[AgentType.VEHICLE],\n",
    "    no_types=[AgentType.UNKNOWN],\n",
    "    num_workers=0,\n",
    "    cache_location=TRAJDATA_CACHE_DIR,\n",
    "    data_dirs={\n",
    "        \"lyft_sample\": LYFT_SAMPLE_RAW_DATA_DIR,\n",
    "    },\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "batch_eval_dataset = UnifiedDataset(\n",
    "    desired_data=[eval_data],\n",
    "    # desired_dt=0.5,\n",
    "    history_sec=(history_sec, history_sec),\n",
    "    future_sec=(prediction_sec, prediction_sec),\n",
    "    agent_interaction_distances=attention_radius,\n",
    "    incl_robot_future=hyperparams['incl_robot_node'],\n",
    "    incl_map=hyperparams['map_encoding'],\n",
    "    map_params=map_params,\n",
    "    only_predict=[AgentType.VEHICLE],\n",
    "    no_types=[AgentType.UNKNOWN],\n",
    "    num_workers=0,\n",
    "    cache_location=TRAJDATA_CACHE_DIR,\n",
    "    data_dirs={\n",
    "        \"lyft_sample\": LYFT_SAMPLE_RAW_DATA_DIR,\n",
    "    },\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(\n",
    "    eval_dataset: UnifiedDataset,\n",
    "    batch_size: int = 128,\n",
    "    num_workers: int = 0,\n",
    "    shuffle: bool = False\n",
    "):\n",
    "    return data.DataLoader(\n",
    "        eval_dataset,\n",
    "        collate_fn=eval_dataset.get_collate_fn(pad_format=\"right\"),\n",
    "        pin_memory=False if device == 'cpu' else True,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=num_workers\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_list = [\"ml_ade\", \"ml_fde\", \"nll_mean\", \"min_ade_5\", \"min_ade_10\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Online (Per Agent) Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "from scipy import linalg\n",
    "\n",
    "prog = re.compile(\"(.*)/(?P<scene_name>.*)/(.*)$\")\n",
    "\n",
    "def plot_outputs(\n",
    "    eval_dataset: UnifiedDataset,\n",
    "    dataset_idx: int,\n",
    "    model: Trajectron,\n",
    "    model_name: str,\n",
    "    agent_ts: int,\n",
    "    save=True,\n",
    "    extra_str=None,\n",
    "    subfolder=\"\",\n",
    "    filetype=\"png\"\n",
    "):\n",
    "    num_modes = 5\n",
    "    plot_every = 1\n",
    "    plot_square_radius = 75\n",
    "    pred_horizon = 30\n",
    "    batch: AgentBatch = eval_dataset.get_collate_fn(pad_format=\"right\")([eval_dataset[dataset_idx]])\n",
    "    batch_idx = 0\n",
    "  \n",
    "    scene_info_path, _, scene_ts = eval_dataset._data_index[dataset_idx]\n",
    "    scene_name = prog.match(scene_info_path).group(\"scene_name\")\n",
    "    \n",
    "    agent_name = batch.agent_name[0]\n",
    "    agent_type_name = f\"{str(AgentType(batch.agent_type[0].item()))}/{agent_name}\"\n",
    "    print(dataset_idx, scene_name, scene_ts, agent_type_name)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        predictions = model.predict(batch,\n",
    "                                    z_mode=True,\n",
    "                                    gmm_mode=True,\n",
    "                                    full_dist=False,\n",
    "                                    output_dists=False)\n",
    "        prediction = next(iter(predictions.values()))\n",
    "        \n",
    "        prediction_distribution_dict, _ = model.predict(batch,\n",
    "                                      z_mode=False,\n",
    "                                      gmm_mode=False,\n",
    "                                      full_dist=True,\n",
    "                                      output_dists=True)\n",
    "        pred_dist = next(iter(prediction_distribution_dict.values()))\n",
    "    \n",
    "    pi_threshold = 0.0\n",
    "    \n",
    "    batch.to(\"cpu\")\n",
    "    \n",
    "    fig, ax = plt.subplots(dpi=150)\n",
    "    # NOTE: To exactly reproduce the figure from our paper, you must edit the trajdata_vis.plot_agent_batch function\n",
    "    # to accept an optional future_horizon (int) argument which truncates plotting to only the future future_horizon timesteps\n",
    "    # (otherwise it can be a but hard to read the figure when full-length predictions and futures are plotted).\n",
    "    # After making the above change, please add future_horizon=pred_horizon to the plot_agent_batch arguments.\n",
    "    trajdata_vis.plot_agent_batch(batch, batch_idx=batch_idx, ax=ax, show=False, close=False)\n",
    "    \n",
    "    if pred_dist.mus.shape[:2] != (1, 1):\n",
    "        return\n",
    "\n",
    "    means = pred_dist.mus[batch_idx, 0].cpu().numpy()\n",
    "    covs = pred_dist.get_covariance_matrix()[batch_idx, 0].cpu().numpy()\n",
    "    pis = pred_dist.pis_cat_dist.probs[batch_idx, 0].cpu().numpy()\n",
    "\n",
    "    ax.plot(\n",
    "        prediction[batch_idx, 0:pred_horizon:plot_every, 0],\n",
    "        prediction[batch_idx, 0:pred_horizon:plot_every, 1],\n",
    "        color='#2D93AD',\n",
    "        alpha=1,\n",
    "        label=\"Most Likely\"\n",
    "    )\n",
    "    \n",
    "    for z_val in range(min(num_modes, means.shape[1])):\n",
    "        # All pis are the same across time.\n",
    "        pi = pis[0, z_val]\n",
    "        \n",
    "        if pi < pi_threshold:\n",
    "            continue\n",
    "\n",
    "        color = '#9F9FED'\n",
    "\n",
    "        alpha_val = pi\n",
    "        ax.plot(means[0:pred_horizon:plot_every, z_val, 0], means[0:pred_horizon:plot_every, z_val, 1],\n",
    "                    color=color,\n",
    "                    alpha=alpha_val)\n",
    "\n",
    "        for timestep in range(0, min(pred_horizon, means.shape[0]), plot_every):\n",
    "            mean = means[timestep, z_val]\n",
    "            covar = covs[timestep, z_val]\n",
    "\n",
    "            v, w = linalg.eigh(covar)\n",
    "            v = 2. * np.sqrt(2.) * np.sqrt(v)\n",
    "            u = w[0] / linalg.norm(w[0])\n",
    "\n",
    "            # Plot an ellipse to show the Gaussian component\n",
    "            angle = np.arctan2(u[1], u[0])\n",
    "            angle = 180. * angle / np.pi  # convert to degrees\n",
    "            ell = patches.Ellipse(mean, v[0], v[1], 180. + angle,\n",
    "                                    color=color)\n",
    "            ell.set_edgecolor(None)\n",
    "            ell.set_clip_box(ax.bbox)\n",
    "            ell.set_alpha(alpha_val)\n",
    "            ax.add_artist(ell)\n",
    "    \n",
    "    # batch_eval: Dict[str, torch.Tensor] = evaluation.compute_batch_statistics_pt(\n",
    "    #     batch.agent_fut[..., :2],\n",
    "    #     prediction_output_dict=torch.from_numpy(prediction),\n",
    "    #     y_dists=pred_dist\n",
    "    # )\n",
    "    \n",
    "    ax.set_title(None)\n",
    "    # ax.set_title(f\"{scene_name}/t={scene_ts} {agent_type_name}\")\n",
    "    offset = 20\n",
    "    ax.set_xlim((-plot_square_radius+offset, plot_square_radius+offset))\n",
    "    ax.set_ylim((-plot_square_radius, plot_square_radius))\n",
    "    # ax.set_aspect('auto')\n",
    "    \n",
    "    ax.axis('off')\n",
    "    # ax.set_xticklabels([])\n",
    "    # ax.set_yticklabels([])\n",
    "    # ax.set_xlabel(None)\n",
    "    # ax.set_ylabel(None)\n",
    "    \n",
    "    ax.legend(bbox_to_anchor=(1.04, 0.5), loc=\"best\", borderaxespad=0, frameon=False)\n",
    "    # print(model_name, extra_str, batch_eval)\n",
    "    \n",
    "    if save:\n",
    "        fname = f\"figures/{subfolder}{model_name}_{scene_name}_{agent_name}_t{agent_ts}\"\n",
    "        if extra_str:\n",
    "            fname += \"_\" + extra_str\n",
    "        fig.savefig(fname + f\".{filetype}\", bbox_inches=\"tight\")\n",
    "        \n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_agent_plot(\n",
    "    model: Trajectron,\n",
    "    model_name: str,\n",
    "    batch: AgentBatch,\n",
    "    agent_ts: int,\n",
    "    plot=True,\n",
    "):\n",
    "    with torch.no_grad():\n",
    "        if plot:\n",
    "            plot_outputs(online_eval_dataset,\n",
    "                         dataset_idx=batch.data_idx[0].item(),\n",
    "                         model=model,\n",
    "                         model_name=model_name,\n",
    "                         agent_ts=agent_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "online_eval_dataloader = get_dataloader(online_eval_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "adaptive_trajectron.reset_adaptive_info()\n",
    "\n",
    "N_SAMPLES = 1001\n",
    "\n",
    "outer_pbar = tqdm(\n",
    "    online_eval_dataloader,\n",
    "    total=min(N_SAMPLES, len(online_eval_dataloader)),\n",
    "    desc=f'Adaptive Eval PH={prediction_sec}',\n",
    "    position=0,\n",
    ")\n",
    "\n",
    "plot_per_step = True\n",
    "\n",
    "curr_agent: str = None\n",
    "agent_ts: int = 0\n",
    "online_batch: AgentBatch\n",
    "for data_sample, online_batch in enumerate(outer_pbar):\n",
    "    if data_sample >= N_SAMPLES:\n",
    "        outer_pbar.close()\n",
    "        break\n",
    "            \n",
    "    if online_batch.agent_name[0] != curr_agent:\n",
    "        # Resetting the K_n, L_n for each Bayesian last layer.\n",
    "        adaptive_trajectron.reset_adaptive_info()\n",
    "        \n",
    "        # # Resetting the finetune baseline to its base.\n",
    "        # finetune_trajectron, _ = load_model(\n",
    "        #     base_model, device, epoch=base_checkpoint,\n",
    "        #     custom_hyperparams={\"trajdata_cache_dir\": \"/home/bivanovic/.unified_data_cache\",\n",
    "        #                         \"single_mode_multi_sample\": False}\n",
    "        # )\n",
    "        # k0_finetune_trajectron, _ = load_model(\n",
    "        #     k0_model, device, epoch=k0_checkpoint,\n",
    "        #     custom_hyperparams={\"trajdata_cache_dir\": \"/home/bivanovic/.unified_data_cache\",\n",
    "        #                         \"single_mode_multi_sample\": False}\n",
    "        # )\n",
    "\n",
    "        curr_agent = online_batch.agent_name[0]\n",
    "        agent_ts: int = 0\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        # This is the inference call that internally updates L_n and K_n.\n",
    "        adaptive_trajectron.adaptive_predict(\n",
    "            online_batch,\n",
    "            update_mode=UpdateMode.ITERATIVE\n",
    "        )\n",
    "    \n",
    "    # finetune_update(finetune_trajectron, online_batch)\n",
    "    # finetune_last_layer_update(k0_finetune_trajectron, online_batch)\n",
    "    \n",
    "    # # This is effectively measuring number of updates/observed data points.\n",
    "    # agent_ts += 1\n",
    "    \n",
    "    if agent_ts % 1 == 0:\n",
    "        per_agent_plot(adaptive_trajectron, \"Ours\", online_batch, agent_ts, plot=plot_per_step)\n",
    "            \n",
    "    # This is effectively measuring the most-recently seen timestep.\n",
    "    agent_ts += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "582a2cc519722524f94eff7e4ee1cc2d34806c213f7eaf8391fe9bc7bccb4852"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
