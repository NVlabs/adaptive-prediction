{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online Adaptive Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import trajectron.visualization as visualization\n",
    "import trajdata.visualization.vis as trajdata_vis\n",
    "\n",
    "from torch import optim, nn\n",
    "from torch.utils import data\n",
    "from trajdata.data_structures.data_index import AgentDataIndex\n",
    "from tqdm.notebook import tqdm\n",
    "from trajectron.model.model_registrar import ModelRegistrar\n",
    "from trajectron.model.model_utils import UpdateMode\n",
    "from trajectron.model.trajectron import Trajectron\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from typing import Dict, Final, List, Optional\n",
    "from trajdata import UnifiedDataset, AgentType, AgentBatch\n",
    "\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this to suit your computing environment and folder structure!\n",
    "\n",
    "TRAJDATA_CACHE_DIR: Final[str] = \"/home/bivanovic/.unified_data_cache\"\n",
    "LYFT_SAMPLE_RAW_DATA_DIR: Final[str] = \"/home/bivanovic/datasets/lyft/scenes/sample.zarr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = \"models/nusc_mm_base_tpp-11_Sep_2022_19_15_45\"\n",
    "k0_model = \"models/nusc_mm_k0_tpp-12_Sep_2022_00_40_16\"\n",
    "adaptive_model = \"models/nusc_mm_sec4_tpp-13_Sep_2022_11_06_01\"\n",
    "oracle_model = \"models/lyft_mm_base_tpp-11_Sep_2022_18_56_49\"\n",
    "\n",
    "base_checkpoint = 20\n",
    "k0_checkpoint = 20\n",
    "adaptive_checkpoint = 20\n",
    "oracle_checkpoint = 1\n",
    "\n",
    "eval_data = \"lyft_sample-mini_val\"\n",
    "\n",
    "history_sec = 2.0\n",
    "prediction_sec = 6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "AXHLINE_COLORS = {\n",
    "    \"Base\": \"#DD9787\",\n",
    "    \"K0\": \"#A6C48A\",\n",
    "    \"Oracle\": \"#BCB6FF\"\n",
    "}\n",
    "\n",
    "SEABORN_PALETTE = {\n",
    "    \"Finetune\": \"#AA7C85\",\n",
    "    \"K0+Finetune\": \"#2D93AD\",\n",
    "    \"Ours\": \"#67934D\",\n",
    "    \"Ours+Finetune\": \"#FF8E61\",\n",
    "    \"Base\": \"#DD9787\",\n",
    "    \"K0\": \"#A6C48A\",\n",
    "    \"Oracle\": \"#BCB6FF\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_dir: str, device: str, epoch: int = 10, custom_hyperparams: Optional[Dict] = None):\n",
    "    save_path = Path(model_dir) / f'model_registrar-{epoch}.pt'\n",
    "\n",
    "    model_registrar = ModelRegistrar(model_dir, device)\n",
    "    with open(os.path.join(model_dir, 'config.json'), 'r') as config_json:\n",
    "        hyperparams = json.load(config_json)\n",
    "        \n",
    "    if custom_hyperparams is not None:\n",
    "        hyperparams.update(custom_hyperparams)\n",
    "\n",
    "    trajectron = Trajectron(model_registrar, hyperparams, None, device)\n",
    "    trajectron.set_environment()\n",
    "    trajectron.set_annealing_params()\n",
    "\n",
    "    checkpoint = torch.load(save_path, map_location=device)\n",
    "    trajectron.load_state_dict(checkpoint[\"model_state_dict\"], strict=False)\n",
    "\n",
    "    return trajectron, hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda:0'\n",
    "    torch.cuda.set_device(0)\n",
    "else:\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restrict_to_predchal(\n",
    "    dataset: UnifiedDataset,\n",
    "    split: str\n",
    ") -> None:\n",
    "    with open(f'predchal_{split}_index.pkl','rb') as f:\n",
    "        within_challenge_split = pickle.load(f)\n",
    "    \n",
    "    within_challenge_split = [\n",
    "        (dataset.cache_path / scene_info_path, num_elems, elems)\n",
    "        for scene_info_path, num_elems, elems in within_challenge_split\n",
    "    ]\n",
    "    \n",
    "    dataset._scene_index = [orig_path for orig_path, _, _ in within_challenge_split]\n",
    "\n",
    "    # The data index is effectively a big list of tuples taking the form:\n",
    "    # (scene_path: str, index_len: int, valid_timesteps: np.ndarray[, agent_name: str])\n",
    "    dataset._data_index = AgentDataIndex(within_challenge_split, dataset.verbose)\n",
    "    dataset._data_len: int = len(dataset._data_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune_update(model: Trajectron, batch: AgentBatch = None, dataloader: data.DataLoader = None, num_epochs: int = None, update_mode: UpdateMode = UpdateMode.NO_UPDATE) -> float:\n",
    "    if batch is None and dataloader is None:\n",
    "        raise ValueError(\"Only one of batch or dataloader can be passed in.\")\n",
    "    \n",
    "    if dataloader is not None and num_epochs is None:\n",
    "        raise ValueError(\"num_epochs must not be None if dataloader is not None.\")\n",
    "    \n",
    "    lr_scheduler = None\n",
    "    optimizer = optim.Adam([{'params': model.model_registrar.get_all_but_name_match('map_encoder').parameters()},\n",
    "                            {'params': model.model_registrar.get_name_match('map_encoder').parameters(),\n",
    "                             'lr': model.hyperparams['map_enc_learning_rate']/10}],\n",
    "                           lr=model.hyperparams['learning_rate']/10)\n",
    "    # Set Learning Rate\n",
    "    if model.hyperparams['learning_rate_style'] == 'const':\n",
    "        lr_scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=1.0)\n",
    "    elif model.hyperparams['learning_rate_style'] == 'exp':\n",
    "        lr_scheduler = optim.lr_scheduler.ExponentialLR(optimizer,\n",
    "                                                        gamma=model.hyperparams['learning_decay_rate'])\n",
    "    \n",
    "    if batch is not None:\n",
    "        model.step_annealers()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        train_loss = model(batch, update_mode=update_mode)\n",
    "        train_loss.backward()\n",
    "\n",
    "        # Clipping gradients.\n",
    "        if model.hyperparams['grad_clip'] is not None:\n",
    "            nn.utils.clip_grad_value_(model.model_registrar.parameters(), model.hyperparams['grad_clip'])\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        # Stepping forward the learning rate scheduler and annealers.\n",
    "        lr_scheduler.step()\n",
    "    \n",
    "    elif dataloader is not None:\n",
    "        batch: AgentBatch\n",
    "        for batch_idx, batch in enumerate(dataloader):\n",
    "            model.step_annealers()\n",
    "            \n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            train_loss = model(batch)\n",
    "                        \n",
    "            train_loss.backward()\n",
    "\n",
    "            # Clipping gradients.\n",
    "            if model.hyperparams['grad_clip'] is not None:\n",
    "                nn.utils.clip_grad_value_(model.model_registrar.parameters(), model.hyperparams['grad_clip'])\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            # Stepping forward the learning rate scheduler and annealers.\n",
    "            lr_scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune_last_layer_update(model: Trajectron, batch: AgentBatch = None, dataloader: data.DataLoader = None, num_epochs: int = None) -> float:\n",
    "    if batch is None and dataloader is None:\n",
    "        raise ValueError(\"Only one of batch or dataloader can be passed in.\")\n",
    "    \n",
    "    if dataloader is not None and num_epochs is None:\n",
    "        raise ValueError(\"num_epochs must not be None if dataloader is not None.\")\n",
    "    \n",
    "    lr_scheduler = None\n",
    "    optimizer = optim.Adam([{'params': model.model_registrar.get_all_but_name_match('last_layer').parameters()},\n",
    "                            {'params': model.model_registrar.get_name_match('last_layer').parameters(),\n",
    "                             'lr': model.hyperparams['learning_rate']/10}],\n",
    "                           lr=0)\n",
    "    # Set Learning Rate\n",
    "    if model.hyperparams['learning_rate_style'] == 'const':\n",
    "        lr_scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=1.0)\n",
    "    elif model.hyperparams['learning_rate_style'] == 'exp':\n",
    "        lr_scheduler = optim.lr_scheduler.ExponentialLR(optimizer,\n",
    "                                                        gamma=model.hyperparams['learning_decay_rate'])\n",
    "    \n",
    "    if batch is not None:\n",
    "        model.step_annealers()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        train_loss = model(batch)\n",
    "        train_loss.backward()\n",
    "\n",
    "        # Clipping gradients.\n",
    "        if model.hyperparams['grad_clip'] is not None:\n",
    "            nn.utils.clip_grad_value_(model.model_registrar.parameters(), model.hyperparams['grad_clip'])\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        # Stepping forward the learning rate scheduler and annealers.\n",
    "        lr_scheduler.step()\n",
    "            \n",
    "    elif dataloader is not None:\n",
    "        batch: AgentBatch\n",
    "        for batch_idx, batch in enumerate(dataloader):\n",
    "            model.step_annealers()\n",
    "            \n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            train_loss = model(batch)\n",
    "                        \n",
    "            train_loss.backward()\n",
    "\n",
    "            # Clipping gradients.\n",
    "            if model.hyperparams['grad_clip'] is not None:\n",
    "                nn.utils.clip_grad_value_(model.model_registrar.parameters(), model.hyperparams['grad_clip'])\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            # Stepping forward the learning rate scheduler and annealers.\n",
    "            lr_scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for matched scene tags: ['mini_val-lyft_sample-palo_alto']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Agent Data (Serially): 100%|██████████| 20/20 [00:00<00:00, 45270.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 scenes in the scene index.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Agent Data Index (Serially): 100%|██████████| 20/20 [00:00<00:00, 439.18it/s]\n",
      "Structuring Agent Data Index: 100%|██████████| 20/20 [00:00<00:00, 15274.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for matched scene tags: ['mini_val-lyft_sample-palo_alto']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating Agent Data (Serially): 100%|██████████| 20/20 [00:00<00:00, 46345.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 scenes in the scene index.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Agent Data Index (Serially): 100%|██████████| 20/20 [00:00<00:00, 460.41it/s]\n",
      "Structuring Agent Data Index: 100%|██████████| 20/20 [00:00<00:00, 21263.90it/s]\n"
     ]
    }
   ],
   "source": [
    "adaptive_trajectron, hyperparams = load_model(\n",
    "    adaptive_model, device, epoch=adaptive_checkpoint,\n",
    "    custom_hyperparams={\"trajdata_cache_dir\": TRAJDATA_CACHE_DIR,\n",
    "                        \"single_mode_multi_sample\": True}\n",
    ")\n",
    "# For offline test\n",
    "adaptive_finetune_trajectron, _ = load_model(\n",
    "    adaptive_model, device, epoch=adaptive_checkpoint,\n",
    "    custom_hyperparams={\"trajdata_cache_dir\": TRAJDATA_CACHE_DIR,\n",
    "                        \"single_mode_multi_sample\": True}\n",
    ")\n",
    "\n",
    "\n",
    "k0_trajectron, _ = load_model(k0_model, device, epoch=k0_checkpoint,\n",
    "    custom_hyperparams={\"trajdata_cache_dir\": TRAJDATA_CACHE_DIR,\n",
    "                        \"single_mode_multi_sample\": False})\n",
    "k0_finetune_trajectron, _ = load_model(k0_model, device, epoch=k0_checkpoint,\n",
    "    custom_hyperparams={\"trajdata_cache_dir\": TRAJDATA_CACHE_DIR,\n",
    "                        \"single_mode_multi_sample\": False})\n",
    "\n",
    "base_trajectron, _ = load_model(base_model, device, epoch=base_checkpoint,\n",
    "    custom_hyperparams={\"trajdata_cache_dir\": TRAJDATA_CACHE_DIR,\n",
    "                        \"single_mode_multi_sample\": False})\n",
    "finetune_trajectron, _ = load_model(base_model, device, epoch=base_checkpoint,\n",
    "    custom_hyperparams={\"trajdata_cache_dir\": TRAJDATA_CACHE_DIR,\n",
    "                        \"single_mode_multi_sample\": False})\n",
    "\n",
    "oracle_trajectron, _ = load_model(oracle_model, device, epoch=oracle_checkpoint,\n",
    "    custom_hyperparams={\"trajdata_cache_dir\": TRAJDATA_CACHE_DIR,\n",
    "                        \"single_mode_multi_sample\": False})\n",
    "\n",
    "# Load training and evaluation environments and scenes\n",
    "attention_radius = defaultdict(lambda: 20.0) # Default range is 20m unless otherwise specified.\n",
    "attention_radius[(AgentType.PEDESTRIAN, AgentType.PEDESTRIAN)] = 10.0\n",
    "attention_radius[(AgentType.PEDESTRIAN, AgentType.VEHICLE)] = 20.0\n",
    "attention_radius[(AgentType.VEHICLE, AgentType.PEDESTRIAN)] = 20.0\n",
    "attention_radius[(AgentType.VEHICLE, AgentType.VEHICLE)] = 30.0\n",
    "\n",
    "map_params = {\"px_per_m\": 2, \"map_size_px\": 100, \"offset_frac_xy\": (-0.75, 0.0)}\n",
    "\n",
    "online_eval_dataset = UnifiedDataset(\n",
    "    desired_data=[eval_data],\n",
    "    history_sec=(0.1, history_sec),\n",
    "    future_sec=(prediction_sec, prediction_sec),\n",
    "    agent_interaction_distances=attention_radius,\n",
    "    incl_robot_future=hyperparams['incl_robot_node'],\n",
    "    incl_raster_map=hyperparams['map_encoding'],\n",
    "    raster_map_params=map_params,\n",
    "    only_predict=[AgentType.VEHICLE],\n",
    "    no_types=[AgentType.UNKNOWN],\n",
    "    num_workers=0,\n",
    "    cache_location=TRAJDATA_CACHE_DIR,\n",
    "    data_dirs={\n",
    "        \"lyft_sample\": LYFT_SAMPLE_RAW_DATA_DIR,\n",
    "    },\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "batch_eval_dataset = UnifiedDataset(\n",
    "    desired_data=[eval_data],\n",
    "    history_sec=(history_sec, history_sec),\n",
    "    future_sec=(prediction_sec, prediction_sec),\n",
    "    agent_interaction_distances=attention_radius,\n",
    "    incl_robot_future=hyperparams['incl_robot_node'],\n",
    "    incl_raster_map=hyperparams['map_encoding'],\n",
    "    raster_map_params=map_params,\n",
    "    only_predict=[AgentType.VEHICLE],\n",
    "    no_types=[AgentType.UNKNOWN],\n",
    "    num_workers=0,\n",
    "    cache_location=TRAJDATA_CACHE_DIR,\n",
    "    data_dirs={\n",
    "        \"lyft_sample\": \"\",\n",
    "    },\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prog = re.compile(\"(.*)/(?P<scene_name>.*)/(.*)$\")\n",
    "\n",
    "def plot_outputs(\n",
    "    eval_dataset: UnifiedDataset,\n",
    "    dataset_idx: int,\n",
    "    model: Trajectron,\n",
    "    model_name: str,\n",
    "    agent_ts: int,\n",
    "    save=True,\n",
    "    extra_str=None,\n",
    "    subfolder=\"\",\n",
    "    filetype=\"png\"\n",
    "):\n",
    "    batch: AgentBatch = eval_dataset.get_collate_fn(pad_format=\"right\")([eval_dataset[dataset_idx]])\n",
    "    with torch.no_grad():\n",
    "        # predictions = model.predict(batch,\n",
    "        #                             z_mode=True,\n",
    "        #                             gmm_mode=True,\n",
    "        #                             full_dist=False,\n",
    "        #                             output_dists=False)\n",
    "        # prediction = next(iter(predictions.values()))\n",
    "        \n",
    "        pred_dists, _ = model.predict(batch,\n",
    "                                      z_mode=False,\n",
    "                                      gmm_mode=False,\n",
    "                                      full_dist=True,\n",
    "                                      output_dists=True)\n",
    "        # pred_dist = next(iter(pred_dists.values()))\n",
    "        \n",
    "    batch.to(\"cpu\")\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    trajdata_vis.plot_agent_batch(batch, batch_idx=0, ax=ax, show=False, close=False)\n",
    "    visualization.visualize_distribution(ax, pred_dists, batch_idx=0)\n",
    "    \n",
    "    # batch_eval: Dict[str, torch.Tensor] = evaluation.compute_batch_statistics_pt(\n",
    "    #     batch.agent_fut[..., :2],\n",
    "    #     prediction_output_dict=torch.from_numpy(prediction),\n",
    "    #     y_dists=pred_dist\n",
    "    # )\n",
    "    \n",
    "    scene_info_path, _, scene_ts = eval_dataset._data_index[dataset_idx]\n",
    "    scene_name = prog.match(scene_info_path).group(\"scene_name\")\n",
    "    \n",
    "    agent_name = batch.agent_name[0]\n",
    "    agent_type_name = f\"{str(AgentType(batch.agent_type[0].item()))}/{agent_name}\"\n",
    "    \n",
    "    ax.set_title(f\"{scene_name}/t={scene_ts} {agent_type_name}\")\n",
    "    # print(model_name, extra_str, batch_eval)\n",
    "    \n",
    "    if save:\n",
    "        fname = f\"plots/{subfolder}{model_name}_{scene_name}_{agent_name}_t{agent_ts}\"\n",
    "        if extra_str:\n",
    "            fname += \"_\" + extra_str\n",
    "        fig.savefig(fname + f\".{filetype}\")\n",
    "        \n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(\n",
    "    eval_dataset: UnifiedDataset,\n",
    "    batch_size: int = 128,\n",
    "    num_workers: int = 0,\n",
    "    shuffle: bool = False\n",
    "):\n",
    "    return data.DataLoader(\n",
    "        eval_dataset,\n",
    "        collate_fn=eval_dataset.get_collate_fn(pad_format=\"right\"),\n",
    "        pin_memory=False if device == 'cpu' else True,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=num_workers\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_list = [\"ml_ade\", \"ml_fde\", \"nll_mean\", \"min_ade_5\", \"min_ade_10\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Online (Per-Agent) Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_results_to_summary(\n",
    "    model_name: str,\n",
    "    overall_summary_dict: Dict[str, List[float]],\n",
    "    model_perf_dict: Dict[AgentType, Dict[str, np.ndarray]]\n",
    "):\n",
    "    overall_summary_dict[\"model\"].append(model_name)\n",
    "    for metric in metrics_list:\n",
    "        overall_summary_dict[metric].append(np.mean(np.concatenate(model_perf_dict[AgentType.VEHICLE][metric])).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005096435546875,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 57,
       "postfix": null,
       "prefix": "Eval Base",
       "rate": null,
       "total": 218,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e1513ddafd44265b2c9efd618a7eeca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval Base:   0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0043239593505859375,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 57,
       "postfix": null,
       "prefix": "Eval K0",
       "rate": null,
       "total": 436,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6289222fcb5f4ee3b8f62752734174d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval K0:   0%|          | 0/436 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0064160823822021484,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 57,
       "postfix": null,
       "prefix": "Eval Oracle",
       "rate": null,
       "total": 218,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e771884ac9f4fde800093d4b2e9c2d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval Oracle:   0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_dict = defaultdict(list)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Base Model\n",
    "    batch_eval_dataloader = get_dataloader(batch_eval_dataset, num_workers=16)\n",
    "    model_perf = defaultdict(lambda: defaultdict(list))\n",
    "    for eval_batch in tqdm(batch_eval_dataloader, desc=f'Eval Base'):\n",
    "        eval_results: Dict[AgentType, Dict[str, torch.Tensor]] = base_trajectron.predict_and_evaluate_batch(eval_batch)\n",
    "        for agent_type, metric_dict in eval_results.items():\n",
    "            for metric, values in metric_dict.items():\n",
    "                model_perf[agent_type][metric].append(values.cpu().numpy())\n",
    "    \n",
    "    add_results_to_summary(\"Base\", eval_dict, model_perf)\n",
    "    \n",
    "    # K0 Model\n",
    "    batch_eval_dataloader = get_dataloader(batch_eval_dataset, batch_size=64, num_workers=8)\n",
    "    model_perf = defaultdict(lambda: defaultdict(list))\n",
    "    for eval_batch in tqdm(batch_eval_dataloader, desc=f'Eval K0'):\n",
    "        eval_results: Dict[AgentType, Dict[str, torch.Tensor]] = k0_trajectron.predict_and_evaluate_batch(eval_batch)\n",
    "        for agent_type, metric_dict in eval_results.items():\n",
    "            for metric, values in metric_dict.items():\n",
    "                model_perf[agent_type][metric].append(values.cpu().numpy())\n",
    "                \n",
    "    add_results_to_summary(\"K0\", eval_dict, model_perf)\n",
    "    \n",
    "    # Oracle Model\n",
    "    batch_eval_dataloader = get_dataloader(batch_eval_dataset, num_workers=8)\n",
    "    model_perf = defaultdict(lambda: defaultdict(list))\n",
    "    for eval_batch in tqdm(batch_eval_dataloader, desc=f'Eval Oracle'):\n",
    "        eval_results: Dict[AgentType, Dict[str, torch.Tensor]] = oracle_trajectron.predict_and_evaluate_batch(eval_batch)\n",
    "        for agent_type, metric_dict in eval_results.items():\n",
    "            for metric, values in metric_dict.items():\n",
    "                model_perf[agent_type][metric].append(values.cpu().numpy())\n",
    "                \n",
    "    add_results_to_summary(\"Oracle\", eval_dict, model_perf)\n",
    "    \n",
    "    del eval_batch\n",
    "    del eval_results\n",
    "    del model_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'model': ['Base', 'K0', 'Oracle'],\n",
       "             'ml_ade': [85.19214630126953,\n",
       "              48.29320526123047,\n",
       "              2.1609904766082764],\n",
       "             'ml_fde': [179.68934631347656,\n",
       "              89.61846160888672,\n",
       "              5.328505516052246],\n",
       "             'nll_mean': [7.990538120269775,\n",
       "              10.895771026611328,\n",
       "              0.7372894287109375],\n",
       "             'min_ade_5': [48.203311920166016,\n",
       "              35.55550003051758,\n",
       "              1.2764157056808472],\n",
       "             'min_ade_10': [38.24354553222656,\n",
       "              25.114696502685547,\n",
       "              1.0219292640686035]})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"results/base_performance.pkl\", 'wb') as f:\n",
    "    pickle.dump(eval_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results/base_performance.pkl\", 'rb') as f:\n",
    "    eval_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'model': ['Base', 'K0', 'Oracle'],\n",
       "             'ml_ade': [85.19214630126953,\n",
       "              48.29320526123047,\n",
       "              2.1609904766082764],\n",
       "             'ml_fde': [179.68934631347656,\n",
       "              89.61846160888672,\n",
       "              5.328505516052246],\n",
       "             'nll_mean': [7.990538120269775,\n",
       "              10.895771026611328,\n",
       "              0.7372894287109375],\n",
       "             'min_ade_5': [48.203311920166016,\n",
       "              35.55550003051758,\n",
       "              1.2764157056808472],\n",
       "             'min_ade_10': [38.24354553222656,\n",
       "              25.114696502685547,\n",
       "              1.0219292640686035]})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_calibration_values(model: Trajectron, dataloader: data.DataLoader):\n",
    "    est_probs = list()\n",
    "    \n",
    "    for batch in tqdm(dataloader, leave=False):\n",
    "        batch.to(model.device)\n",
    "        \n",
    "        node_type: AgentType\n",
    "        for node_type in batch.agent_types():\n",
    "            mgcvae = model.node_models_dict[node_type.name]\n",
    "\n",
    "            agent_type_batch = batch.for_agent_type(node_type)\n",
    "            ph = agent_type_batch.agent_fut.shape[1]\n",
    "\n",
    "            # Run forward pass\n",
    "            y_dists, _ = mgcvae.predict(agent_type_batch,\n",
    "                                        prediction_horizon=ph,\n",
    "                                        num_samples=1,\n",
    "                                        z_mode=False,\n",
    "                                        gmm_mode=False,\n",
    "                                        full_dist=True,\n",
    "                                        output_dists=True)\n",
    "            \n",
    "            estimated_prob = y_dists.quantile(batch.agent_fut[..., :2])\n",
    "            est_probs.extend(estimated_prob.flatten().tolist())\n",
    "    \n",
    "    return np.asarray(est_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c35e4f436e574731bd2187e1df94d7d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b7cde9c40e34beb99dc0f5bb60f2d78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6a19a70ac00444cb4c41d2a9d9f913a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "calib_values = list()\n",
    "\n",
    "with torch.no_grad():\n",
    "    base_calib = compute_calibration_values(base_trajectron, get_dataloader(batch_eval_dataset, num_workers=16))\n",
    "\n",
    "    batch_dataloader = get_dataloader(batch_eval_dataset, num_workers=8)\n",
    "    k0_calib = compute_calibration_values(k0_trajectron, batch_dataloader)\n",
    "    oracle_calib = compute_calibration_values(oracle_trajectron, batch_dataloader)\n",
    "\n",
    "calib_values.append((0, base_calib, k0_calib, oracle_calib))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibration_plot(est_gt_probs: np.ndarray, method_name: str, ax):\n",
    "    thresholds = np.linspace(0, 1, 101)\n",
    "    \n",
    "    num_gt_points = est_gt_probs.shape[0]\n",
    "    # Commenting this out, although it could be used to scale to the max PDF height.\n",
    "    # No need though, without it we can see overconfidence easier.\n",
    "    # max_pdf = est_gt_probs.max()\n",
    "    \n",
    "    fraction_gt_included = [(est_gt_probs >= threshold).sum() / num_gt_points for threshold in thresholds]\n",
    "    \n",
    "    ax.plot(thresholds, fraction_gt_included, label=method_name, lw=3, c=SEABORN_PALETTE[method_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_calibration_plots(base_calib, k0_calib, oracle_calib, ours_calib, ours_finetune_calib, finetune_calib, k0_finetune_calib, num_updates):\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    ax.plot([0, 1], [1, 0], label=\"Ideal\", ls=\"--\", c=\"k\")\n",
    "\n",
    "    calibration_plot(base_calib, \"Base\", ax)\n",
    "    calibration_plot(k0_calib, \"K0\", ax)\n",
    "    calibration_plot(oracle_calib, \"Oracle\", ax)\n",
    "    calibration_plot(ours_finetune_calib, \"Ours+Finetune\", ax)\n",
    "    calibration_plot(ours_calib, \"Ours\", ax)\n",
    "    calibration_plot(finetune_calib, \"Finetune\", ax)\n",
    "    calibration_plot(k0_finetune_calib, \"K0+Finetune\", ax)\n",
    "\n",
    "    ax.legend(bbox_to_anchor=(1.04, 0.5), loc=\"center left\", borderaxespad=0)\n",
    "    ax.set_xlabel(\"Probability Threshold\")\n",
    "    ax.set_ylabel(\"Fraction of GT Points\")\n",
    "\n",
    "    ax.grid(False)\n",
    "    \n",
    "    # fig.savefig(f\"results/calib_after{num_updates}.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "926d16e106994e49904da276d19cfef0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adaptive Eval PH=6.0:   0%|          | 0/1001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed8a1b11418f4486a37a0c2dd6e3e464",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17ef1d8fa419452c88a4de2f10513df5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7afa99b496cb407c9fcfd2febaed630e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "def55daaafd74233b73203d8eddcc352",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92100ff8445842e0a2d65e520d1ddef8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4de89635753a480d936b9d07b2c0465f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ffe7ef93e5245998e1545f835595e1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52e728a3377940a29293ed24aa45e10e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2ae1b4ded98401aa4d2e80a85aaf785",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c926e5a93494c7f8519bc6295fc5b1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70cc77172b4e49cba597da2b02bb130e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcd0b6cc3f75400d9d33582e2c74f726",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6963647d9bc242e7bd06f432a251f047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45ac500421a4489a97ccc8ec7ec478e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14c0e951493d46179215c918ce0f9018",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bece1244395f4caf83b35b131b3ee3a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0e797241a4443dabc3529eaadc8d549",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36411d46225444f5a061c90ff5795416",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f19e2a42a554064bac2d1c2da177f10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dcd55e8dc894b0d88ec29fc5c284dd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d57b1466406499a906d021729b7c017",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "755d0a7609024d2797907764591f1352",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8298ab4900b64f25a4b41b1fc1847c65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b42b9f6a957b4f76a6ac207d780ac4ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fa345f1970f413cb1e88d32bfcb572f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29abac59c38a413eade969ca9d922eb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67deedb025e543b4bc93ce8b67d89103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0999c4eb5d240c6b161b0dcf84f2ae3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2108233587334b89b81bb826ca1344b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c11831c7d6314530b9280a008e4401e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ea78725a1f247dab936400df01ed1a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9398f6f47d3f4580adcf809d9709ebc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a551e955c9c64be8a6bae13b464119b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2460b5f945804261bbb667d50d463a3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da126dc7184147209be1350cfd82dab2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "702374cc3d2d498caf2b119f293cabbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5789350deab347bf8718bce1d21289fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d070bbd36d5405bb73af204f8383876",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d80158b315d64f41b473f59fe14efa98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bbe59de314c406ebd0c3ea879e5e0f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "541e62988656432389157c8af0794fef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e59c86aa2544d2b85268a1ae14d9b62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5b30b1154bd4ff4a433a65c42c913df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "online_eval_dataloader = get_dataloader(online_eval_dataset, batch_size=1, shuffle=True)\n",
    "batch_eval_dataloader = get_dataloader(batch_eval_dataset, num_workers=8)\n",
    "\n",
    "adaptive_trajectron.reset_adaptive_info()\n",
    "adaptive_finetune_trajectron.reset_adaptive_info()\n",
    "\n",
    "# Resetting the finetune baselines to their base.\n",
    "finetune_trajectron, _ = load_model(base_model, device, epoch=base_checkpoint,\n",
    "    custom_hyperparams={\"trajdata_cache_dir\": TRAJDATA_CACHE_DIR,\n",
    "                        \"single_mode_multi_sample\": False})\n",
    "k0_finetune_trajectron, _ = load_model(k0_model, device, epoch=k0_checkpoint,\n",
    "    custom_hyperparams={\"trajdata_cache_dir\": TRAJDATA_CACHE_DIR,\n",
    "                        \"single_mode_multi_sample\": False})\n",
    "\n",
    "N_SAMPLES = 1001\n",
    "\n",
    "outer_pbar = tqdm(\n",
    "    online_eval_dataloader,\n",
    "    total=min(N_SAMPLES, len(online_eval_dataloader)),\n",
    "    desc=f'Adaptive Eval PH={prediction_sec}',\n",
    "    position=0,\n",
    ")\n",
    "\n",
    "plot_per_eval = False\n",
    "\n",
    "online_batch: AgentBatch\n",
    "for data_sample, online_batch in enumerate(outer_pbar):\n",
    "    if data_sample >= N_SAMPLES:\n",
    "        outer_pbar.close()\n",
    "        break\n",
    "    \n",
    "    if data_sample == 0:\n",
    "        ours_calib = compute_calibration_values(adaptive_trajectron, batch_eval_dataloader)\n",
    "        finetune_calib = compute_calibration_values(finetune_trajectron, batch_eval_dataloader)\n",
    "        k0_finetune_calib = compute_calibration_values(k0_finetune_trajectron, batch_eval_dataloader)\n",
    "        \n",
    "        calib_values.append((data_sample, ours_calib, ours_calib, finetune_calib, k0_finetune_calib))\n",
    "        \n",
    "        # make_calibration_plots(base_calib, k0_calib, oracle_calib, ours_calib, finetune_calib, k0_finetune_calib, data_sample)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # This is the inference call that internally updates L_n and K_n.\n",
    "        adaptive_trajectron.adaptive_predict(\n",
    "            online_batch,\n",
    "            update_mode=UpdateMode.ITERATIVE\n",
    "        )\n",
    "    \n",
    "    if data_sample < 101:\n",
    "        with torch.no_grad():\n",
    "            adaptive_finetune_trajectron.adaptive_predict(\n",
    "                online_batch,\n",
    "                update_mode=UpdateMode.ITERATIVE\n",
    "            )\n",
    "    else:\n",
    "        finetune_update(adaptive_finetune_trajectron, online_batch, update_mode=UpdateMode.NO_UPDATE)\n",
    "\n",
    "    finetune_update(finetune_trajectron, online_batch)\n",
    "    finetune_last_layer_update(k0_finetune_trajectron, online_batch)\n",
    "    \n",
    "    if (data_sample + 1) % 100 == 0:    \n",
    "        ours_calib = compute_calibration_values(adaptive_trajectron, batch_eval_dataloader)\n",
    "        ours_finetune_calib = compute_calibration_values(adaptive_finetune_trajectron, batch_eval_dataloader)\n",
    "        finetune_calib = compute_calibration_values(finetune_trajectron, batch_eval_dataloader)\n",
    "        k0_finetune_calib = compute_calibration_values(k0_finetune_trajectron, batch_eval_dataloader)\n",
    "        \n",
    "        calib_values.append((data_sample, ours_calib, ours_finetune_calib, finetune_calib, k0_finetune_calib))\n",
    "        \n",
    "        # make_calibration_plots(base_calib, k0_calib, oracle_calib, ours_calib, ours_finetune_calib, finetune_calib, k0_finetune_calib, data_sample + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"results/model_calibrations.pkl\", 'wb') as f:\n",
    "    pickle.dump(calib_values, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "582a2cc519722524f94eff7e4ee1cc2d34806c213f7eaf8391fe9bc7bccb4852"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
